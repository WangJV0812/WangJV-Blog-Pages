<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.148.2"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>WangJV Blog</title><meta name=keywords content="blog,computer graphics,machine learning,mathematics"><meta name=description content="WangJV's personal blog about computer graphics, machine learning and mathematics"><meta name=author content="WangJV"><link rel=canonical href=https://wangjv0812.github.io/WangJV-Blog-Pages/><link crossorigin=anonymous href=https://wangjv0812.github.io/WangJV-Blog-Pages/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://wangjv0812.github.io/WangJV-Blog-Pages/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangjv0812.github.io/WangJV-Blog-Pages/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangjv0812.github.io/WangJV-Blog-Pages/favicon-32x32.png><link rel=apple-touch-icon href=https://wangjv0812.github.io/WangJV-Blog-Pages/apple-touch-icon.png><link rel=mask-icon href=https://wangjv0812.github.io/WangJV-Blog-Pages/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangjv0812.github.io/WangJV-Blog-Pages/index.xml><link rel=alternate type=application/json href=https://wangjv0812.github.io/WangJV-Blog-Pages/index.json><link rel=alternate hreflang=en href=https://wangjv0812.github.io/WangJV-Blog-Pages/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]},loader:{load:["ui/safe"]}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><meta property="og:url" content="https://wangjv0812.github.io/WangJV-Blog-Pages/"><meta property="og:site_name" content="WangJV Blog"><meta property="og:title" content="WangJV Blog"><meta property="og:description" content="WangJV's personal blog about computer graphics, machine learning and mathematics"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta property="og:image" content="https://wangjv0812.github.io/WangJV-Blog-Pages/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://wangjv0812.github.io/WangJV-Blog-Pages/"><meta name=twitter:title content="WangJV Blog"><meta name=twitter:description content="WangJV's personal blog about computer graphics, machine learning and mathematics"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"WangJV Blog","url":"https://wangjv0812.github.io/WangJV-Blog-Pages/","description":"WangJV's personal blog about computer graphics, machine learning and mathematics","logo":"https://wangjv0812.github.io/WangJV-Blog-Pages/favicon.ico","sameAs":[]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangjv0812.github.io/WangJV-Blog-Pages/ accesskey=h title="WangJV Blog (Alt + H)">WangJV Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangjv0812.github.io/WangJV-Blog-Pages/ title=Home><span>Home</span></a></li><li><a href=https://wangjv0812.github.io/WangJV-Blog-Pages/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://wangjv0812.github.io/WangJV-Blog-Pages/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://wangjv0812.github.io/WangJV-Blog-Pages/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://wangjv0812.github.io/WangJV-Blog-Pages/search/ title="🔍 Search (Alt + /)" accesskey=/><span>🔍 Search</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>From Transformer to VGGT</h2></header><div class=entry-content><p>1. Preliminary: Attention and ViT 我们先来回顾一下经典的 Transformer 结构，之后从 Transformer 的角度来理解 ViT，这样大家能更好的理解 VGGT 和 MASt3R、DUSt3R 之类工作的苦恼之处。
1.1. Encoder and Decoder 深度学习名著 《Attention is all you need》 提出的古典派 Attention（这么说是因为由于 Transformer 的大火，Attention 机制的变种已经太多了，我们只关注最经典的架构就好，其他都大同小异）。最经典的 Transformer 致力于解决翻译问题，是一个十分经典的 nlp 问题，采用了最经典的 Encoder-Decoder 结构。
Encoder 由 6 个完全相同的层堆叠而成，每个层由两个子层组成。第一个层负责实现 multi-head self-attention 机制；第二个层是一个简单的全连接前馈网络。为了避免在训练中出现梯度消失的问题，Transformer 在子层间采用了残差链接，之后对子层的输出做归一化（即 Add&amp;Norm）那个块。因此，每个子层的输出可以表示为：
$$ \text{LayerNorm}(x+\text{Sublayer}(x)) $$其中 $\text{Sublayer}(x)$ 是每个子层具体的实现。为了方便残差链接，每层的输出和输入（包括 embedding layers）都被约定为 $d_{module} = 512$。（至少 Attention is all you need 是这样的）。
Decoder 也是由完全相同的层堆叠而成，和 Encoder 不同的是 Decoder 的每个层也有三个子层。Decoder 的第一个子层是 masked multi-head self-attention，负责对输入的 embedding 做自注意力机制，之后将输入的 embedding 和 encoder 编码的结合结合起来。后面的层和 Encoder 一样，都是 multi-head self-attention 和前馈网络的组合。
...</p></div><footer class=entry-footer><span title='2025-04-18 16:40:25 +0800 +0800'>April 18, 2025</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1713 words&nbsp;·&nbsp;WangJV</footer><a class=entry-link aria-label="post link to From Transformer to VGGT" href=https://wangjv0812.github.io/WangJV-Blog-Pages/2025/04/from-transformer-to-vggt/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DUSt3R and MUSt3R</h2></header><div class=entry-content><p>1. DUSt3R 1.1. Introduction 一般而言，现代的 MVS 和 SFM 的流程总是可以总结为以下几个子问题
特征点匹配 寻找本质矩阵 对点进行三角测量 对场景进行稀疏重建 估计相机参数， 密集重建 但是在这个复杂的过程中，每个子问题都对原始问题做了简化，无法完美解决，为后面的步骤引入了噪声，从而导致整个系统显的“精致而脆弱”。在这方面，每个子问题之间缺乏沟通就很能说明问题：如果能将这些缓解紧耦合到一起，将噪声统一的，全局的考虑，可以很大程度上解决应为过度简化和解耦导致的种种问题。此外，这个流程中的关键步骤很脆弱，在很多情况下容易出错。例如，很多 SFM 方法都依赖于相机参数的估计，但是如果遇到观察比较少、非漫反射表面或者相机姿态运动较为单一时，相机参数估计可能失效，导致整个 SFM 过程都会失效。归根结底：一个多视图立体视觉（MVS）算法的性能仅取决于输入图像和相机参数的质量
事实上，单张图或者多张图哦通过深度学习的方式提取深度并不罕有。但是在不引入额外的先验信息时，这个问题往往是不适定的，所以这些方法利用神经网络从大量数据中学习巨量的三维先验知识来解决模糊性问题。这些方法可以分为两类。第一类利用类别级别的物体先验知识，事实上 DreamFusion 就属于这类工作，可以从单张照片或者一句自然语言描述生成三纬结构。另一种与 DUSt3R 较为类似，系统的学习一般的场景来实现单目深度估计。但是一般而言，例如 SuperGlue 之类，在训练和推理过程中，都没有显然的引入三维结构的信息，也没有扔掉相机矩阵的桎梏。可以说，DUSt3R 是一种基于深度学习的 ALL in One 的深度估计方法，入了点图（Point Map）表示，使网络能够在规范框架中预测三维形状。
1.2. Method and forward 1.2.1. Ponit Map 接下来，我们将图片中每个像素对应的三维点构成的集合称为 点图（point map） $X \in R^{W×H×3}$。与分辨率为 $W×H$的对应RGB图像 $I$相关联，点图 $X$ 在图像像素与三维点之间形成一一映射，即对于所有像素坐标 $(i, j) \in \{1...W\}×\{1...H\}$，都有 $I_{i,j} \leftrightarrow X_{i,j}$。此处每个像素点对应于一个三维点实事丧引入了一个简化假设，即假设观测的场景全部是不透明且漫反射的，不存在透过某个物体并观察到另一个物体的情况。
1.2.2. 相机和场景 相机与场景。给定相机内参 $K \in \mathbb{R}^{3 ×3}$ ，所观测场景的点图 $X$ 可以直接从真实深度图：
$$ D \in \mathbb{R}^{W ×H} $$中获取，其公式为
...</p></div><footer class=entry-footer><span title='2025-03-10 16:40:25 +0800 +0800'>March 10, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;903 words&nbsp;·&nbsp;WangJV</footer><a class=entry-link aria-label="post link to DUSt3R and MUSt3R" href=https://wangjv0812.github.io/WangJV-Blog-Pages/2025/03/dust3r-and-must3r/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>homography</h2></header><div class=entry-content><p>假设我们有两个坐标系 $\mathcal F_a, \ \mathcal F_b$，有一个点 $P$ 在一个平面上。在两个坐标系下，这个点可以描述为 $\rho_a, \rho_b$；对应的平面可以通过法向量和截距来描述：$\{n_a. d_a\}, \{n_b. d_b\}$。
此外，该点有在图像坐标系下的描述 $p_a, p_b$ 和对应的相机矩阵 $K_a, K_b$。那么可以写出：
$$ \begin{aligned} p_a = \frac{1}{z_a} K_a \rho_a \\ p_b = \frac{1}{z_b} K_b \rho_b \end{aligned} $$此外， 由于该点在对应的平面上，有平面约束：
$$ \begin{aligned} n^T_a \rho_a + d_a = 0 \\ n^T_b \rho_b + d_b = 0 \end{aligned} $$那么，将平面约束中的 $\rho$ 通过投影矩阵转换为像素坐标，有：
$$ \begin{aligned} &amp;z_a n^T_a K_a^{-1} p_a + d_a = 0\\ &amp;z_a = -\frac{d_a}{n^T_a K_a^{-1} p_a}\\ &amp;z_b n^T_b K_b^{-1} p_b + d_b = 0\\ &amp;z_b = -\frac{d_b}{n^T_b K_b^{-1} p_b}\\ \end{aligned} $$带入到 $\rho_a, \rho_b$ 的表达式中，有：
...</p></div><footer class=entry-footer><span title='2025-02-14 17:13:56 +0800 +0800'>February 14, 2025</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;236 words&nbsp;·&nbsp;WangJV</footer><a class=entry-link aria-label="post link to homography" href=https://wangjv0812.github.io/WangJV-Blog-Pages/2025/02/homography/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DreamFusion</h2></header><div class=entry-content><p>1. 使用神经网路进行数据生成 使用神经网络生成一个高维度数据是机器学习中非常重要的一个工作。我们假设数据集 $\left\{\boldsymbol{x_1}, \boldsymbol{x_2}, \dots, \boldsymbol{x_n}\right\}$ 为一个大小为$n$的数据集，该数据集统一的服从一个概率分布 $p_{data}(\boldsymbol{x})$ 。我们假设对数据集的抽样都是独立同分布的，即：
$$ \left\{\boldsymbol{x_1}, \boldsymbol{x_2}, \dots, \boldsymbol{x_n}\right\} \sim p_{data}(\boldsymbol{x}) $$那么丛现有数据生成新的数据的核心就是使用神经网络学习这个概率分布。不妨假设学习的概率分布为 $\hat p_\theta(\boldsymbol x)$。我们会希望 $\hat p_\theta(\boldsymbol x)$ 尽可能的接近 $p_{data}(\boldsymbol(x))$ 。为了衡量真是分布和我们学习的分布之间的差距，我们需要定义一个距离函数 $D(\cdot \mid \cdot)$ 我们可以定义优化目标：
$$ \hat \theta = \arg \min_{\theta} D\left(p_{data}(\boldsymbol{x}) \mid \hat p_\theta(\boldsymbol x) \right) $$关于距离函数，我们可以定义 $D(\cdot \mid \cdot)$ 为 f-divergence 定义为：
$$ D_f(p_{data}(\boldsymbol(x)) \mid \hat p_\theta(\boldsymbol x)) = \int p_\theta(\boldsymbol x) f \left(\frac{p_{data}(\boldsymbol x)}{p_\theta(\boldsymbol x)}\right) d\boldsymbol x $$不妨取 $f(x) = x\log x$ ，我们可以得到 KL 散度：
...</p></div><footer class=entry-footer><span title='2024-12-18 16:40:25 +0800 +0800'>December 18, 2024</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;2442 words&nbsp;·&nbsp;WangJV</footer><a class=entry-link aria-label="post link to DreamFusion" href=https://wangjv0812.github.io/WangJV-Blog-Pages/2024/12/dreamfusion/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Kalman_filter</h2></header><div class=entry-content><p>ps: 为了更快的写出来这个文档，我不会很注意公式的粗细体，请见谅。
1. 最大后验估计 1.1. 状态估计问题描述 我们假设有一个线性系统，其噪声可以用高斯函数来描述。这个线性系统可以如下描述：
$$ \begin{array}{l} x_k = A_{k-1}x_{k-1} + v_k + \omega_k\\ y_k = Cx_k + n_k \end{array} $$其中，有：
$$ \begin{array}{ll} \text{初始噪声} & x_0 \sim \mathcal G (x \mid 0, P_0) \\ \text{过程噪声} & x_k \sim \mathcal G (x \mid 0, Q_k) \\ \text{观测噪声} & \omega_k \sim \mathcal G (x \mid 0, R_k) \end{array} $$我们认为除了系统的输入 $v_k$ 之外，其余所有变量皆为随机变量。此外我们称 $A_k$ 为状态转移矩阵，$C_k$ 为观测矩阵。对于这个系统而言，系统的初始状态 $x_0$、系统输入 $v_k$ 和 系统输出是已知的。状态估计的目标就是通过这些已知的参数，估计出系统的状态 $x_k$。
1.2. 最大后验估计 最大后验估计需要完成如下一个优化问题：
...</p></div><footer class=entry-footer><span title='2024-11-04 16:40:25 +0800 +0800'>November 4, 2024</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1724 words&nbsp;·&nbsp;WangJV</footer><a class=entry-link aria-label="post link to Kalman_filter" href=https://wangjv0812.github.io/WangJV-Blog-Pages/2024/11/kalman_filter/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://wangjv0812.github.io/WangJV-Blog-Pages/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://wangjv0812.github.io/WangJV-Blog-Pages/page/3/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangjv0812.github.io/WangJV-Blog-Pages/>WangJV Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>