<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>数学 on WangJV Blog</title><link>https://wangjv0812.cn/tags/%E6%95%B0%E5%AD%A6/</link><description>Recent content in 数学 on WangJV Blog</description><image><title>WangJV Blog</title><url>https://wangjv0812.cn/</url><link>https://wangjv0812.cn/</link></image><generator>Hugo -- 0.150.0</generator><language>en-us</language><lastBuildDate>Sat, 13 Sep 2025 17:13:56 +0800</lastBuildDate><atom:link href="https://wangjv0812.cn/tags/%E6%95%B0%E5%AD%A6/index.xml" rel="self" type="application/rss+xml"/><item><title>Fisher Information and Fisher Divergence</title><link>https://wangjv0812.cn/2025/09/fisher-information-and-fisher-divergence/</link><pubDate>Sat, 13 Sep 2025 17:13:56 +0800</pubDate><guid>https://wangjv0812.cn/2025/09/fisher-information-and-fisher-divergence/</guid><description>&lt;p&gt;在开始长篇大论之前，不妨先对费雪信息 (Fisher Information) 和 费雪散度 (Fisher Divergence) 有一个先验的、直观的理解。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fisher Information 衡量的是对于一个概率分布模型，它的参数有多么敏感或者说确定。信息量越大，我们用数据来估计这个参数时就越有信心。&lt;/li&gt;
&lt;li&gt;Fisher Divergence 衡量的是两个不同的概率分布，它们的“形状”有多么相似。散度越小，两个分布越接近。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面则给出一些不那么直观的，数学形式上的解释。&lt;/p&gt;
&lt;h2 id="1-statistical-manifold"&gt;1. Statistical Manifold&lt;/h2&gt;
&lt;p&gt;和之前我们讨论的数据分布流形一样，我们可以认为，一种类别的概率分布（例如高斯分布），控制分布的参数同样可以构成一个流形。我们不妨就拿高斯分布举例子，对于一个标准的一维高斯分布，其受到参数 $\sigma^2, \mu$ 控制。那么所有的高斯分布的参数 $\sigma^2, \mu$ 所构成的空间便形成一个 “统计流形”。&lt;/p&gt;
&lt;p&gt;那么如果对于一族分布（或者任意分布），我们希望测量两个分布的差异（这在 Learning 中是十分常用的，可以度量两个分布的差异，就可以驱动优化）。定义分布的差异事实上就是希望可以在统计流形上定义一个有效的度量。&lt;/p&gt;
&lt;h2 id="2-score-function"&gt;2. Score Function&lt;/h2&gt;
&lt;p&gt;对于一个受到参数 $\theta$ 控制，关于随机变量 $x$ 的分布 $q(x; \theta)$，我们可以定义其 Score Function：&lt;/p&gt;
$$
\begin{gather}
s_\theta(x, \theta) = \nabla_\theta \log q(x; \theta)\\
s_x(x, \theta) = \nabla_x \log q(x; \theta)\\
\end{gather}
$$&lt;p&gt;对于 score function，我们可以从两个 level 理解它。&lt;/p&gt;
&lt;p&gt;首先，直观的、几何的讲，对于 score function $s_x(x, \theta)$ 可以理解为定义在数据空间上的切向量场。不妨想象一下，概率密度 $q(x, \theta)$ 在数据空间中形成了一座 “高山”，向量 $s_x(x, \theta)$ 方向指向的是概率密度对数增长最快的方向。$s_x(x, \theta)$ 告诉我们数据点向哪个方向 ”移动“，概率变大的最快。类似的，$s_\theta(x, \theta)$ 则是在参数空间中的切向量场，指向的是关于参数 $\theta$ 的概率密度对数增长最快的方向。&lt;/p&gt;</description></item><item><title>Naive Group Theory</title><link>https://wangjv0812.cn/2025/06/naive-group-theory/</link><pubDate>Wed, 25 Jun 2025 17:13:56 +0800</pubDate><guid>https://wangjv0812.cn/2025/06/naive-group-theory/</guid><description>&lt;p&gt;我们知道，李群实质上是在一个微分流形性质的群。可以看到，李群实质上是 &lt;strong&gt;群&lt;/strong&gt; 和 &lt;strong&gt;微分流形&lt;/strong&gt; 的交集。想要搞明白微分流形是什么并不容易，这需要学习关于微分几何的知识。但是幸运的是，李群研究研究并没有那么依赖于微分流形的知识（事实上这样说并不准确，但是我们尽量不涉及）。和微分几何相比，群的知识就简单的多了。只要捋清概念，即便是中学生也可以明白。&lt;/p&gt;
&lt;p&gt;事实上群被描述为一个带有一个运算（或者说二元关系）的集合，这个集合和其上定义的二元运算需要满足四个基本性质。我们将集合标记为 $C$，二元运算为 $[\cdot\ ,\ \cdot]$。需要满足的性质为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;封闭性：$\forall c_1, c_2 \in C, [c_1, c_2] \in C$&lt;/li&gt;
&lt;li&gt;结合律：$\forall c_1, c_2, c_3 \in C, [[c_1, c_2], c_3 ] = [c_1, [c_2, c_3]]$&lt;/li&gt;
&lt;li&gt;单位元：$\forall c \in C, \exists e \in C, \text{ s.t. } ce = ec = c$&lt;/li&gt;
&lt;li&gt;逆元：$\forall c_1 \in C, \exists c_2 \in C, c_1c_2 = c_2c_1 = e$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在研究群的性质时，我们需要清晰的认识到 &lt;strong&gt;集合&lt;/strong&gt; 和 定义在集合上的 &lt;strong&gt;二元运算&lt;/strong&gt; 是同样重要的。最初提出群这个概念是诶了解决对称性问题，这种对称性关系实质上是研究一种数学结构上的 “&lt;strong&gt;操作不变形&lt;/strong&gt;”。即在一个元素操作前后的结果是完全相同的，我们就称这两个元素在操作上是 “对称” 的。例如对于一个球，在任意元素在球心上做“旋转” 操作，球本身是完全不变的，我们可以称“球”构成的集合 在 “过圆心旋转” 这样操作下，是对称的。&lt;/p&gt;
&lt;p&gt;另一个很经典的例子是用群来描述等边三角形的旋转不变形。但是这个例子我们后面再补充&lt;/p&gt;
&lt;h2 id="1-群的结构和基本操作"&gt;1. 群的结构和基本操作&lt;/h2&gt;
&lt;h3 id="11-子群"&gt;1.1. 子群&lt;/h3&gt;
&lt;p&gt;对于集合 $G$ 的一个子集 $H \subset G$，在群 $G$ 定义的运算律 $\cdot$ 上满足群的性质，就称 $H$ 为 $G$ 的子群。不难察觉到，单位元 $e$ 一定在 $H$ 上。例如任意通过坐标原点的直线都可以看作定义在加法上的对 $R(2)$ 的子群。&lt;/p&gt;</description></item><item><title>3D Kinematics and Dynamics</title><link>https://wangjv0812.cn/2025/06/3d-kinematics-and-dynamics/</link><pubDate>Fri, 20 Jun 2025 17:13:56 +0800</pubDate><guid>https://wangjv0812.cn/2025/06/3d-kinematics-and-dynamics/</guid><description>深入探讨三维空间中的运动学和动力学基础，包括旋转矩阵、四元数和李群理论</description></item><item><title>Mathematics In 3DGS 2</title><link>https://wangjv0812.cn/2024/05/mathematics-in-3dgs-2/</link><pubDate>Fri, 17 May 2024 17:13:56 +0800</pubDate><guid>https://wangjv0812.cn/2024/05/mathematics-in-3dgs-2/</guid><description>&lt;h2 id="1-矩阵求导的常用方法"&gt;1. 矩阵求导的常用方法&lt;/h2&gt;
&lt;h3 id="11-矩阵求导的一般方法"&gt;1.1. 矩阵求导的一般方法&lt;/h3&gt;
&lt;p&gt;在矩阵论的课程中，我们学习过如下几种分析相关的知识，分别是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;向量对标量求导&lt;/li&gt;
&lt;li&gt;向量对向量求导&lt;/li&gt;
&lt;li&gt;向量对矩阵求导&lt;/li&gt;
&lt;li&gt;矩阵对标量求导&lt;/li&gt;
&lt;li&gt;矩阵对向量求导&lt;/li&gt;
&lt;li&gt;矩阵对矩阵求导&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;事实上不难发现，我们只需要搞明白了矩阵对标量求导和矩阵对矩阵求导的方法，其他问题均可从这个两个原则推理开去。因此我们叙述的重点放在这两个问题上。&lt;/p&gt;
&lt;h4 id="111-矩阵对标量求导"&gt;1.1.1. 矩阵对标量求导&lt;/h4&gt;
&lt;p&gt;假设我们有矩阵 $\mathbf A$ 和标量 $k$，其中矩阵 $\mathbf A$ 的展开形式为：&lt;/p&gt;
$$
\mathbf A=
\left[
\begin{matrix}
a_{11}&amp; a_{12}&amp; \cdots&amp; \ a_{1n} \\
a_{21}&amp; a_{22}&amp; \cdots&amp; \ a_{2n} \\
\vdots&amp; \vdots&amp; \ddots&amp; \vdots \\
a_{n1}&amp; a_{n2}&amp; \cdots&amp; \ a_{nn} \\
\end{matrix}
\right]
$$&lt;p&gt;那么，$\frac{d \mathbf A}{d k}$被定义为：&lt;/p&gt;
$$
\frac{d \mathbf A}{d k} =
\left[
\begin{matrix}
\frac{d a_{11}}{d k}&amp; \frac{d a_{12}}{d k}&amp; \cdots&amp; \ \frac{d a_{1n}}{d k}&amp; \\
\frac{d a_{21}}{d k}&amp; \frac{d a_{22}}{d k}&amp; \cdots&amp; \ \frac{d a_{2n}}{d k}&amp; \\
\vdots&amp; \vdots&amp; \ddots&amp; \vdots \\
\frac{d a_{n1}}{d k}&amp; \frac{d a_{n2}}{d k}&amp; \cdots&amp; \ \frac{d a_{nn}}{d k}&amp; \\
\end{matrix}
\right]
$$&lt;p&gt;于上述定义类似，如果标量对矩阵求导，即$\frac{d k}{d \mathbf A}$，其定义为：&lt;/p&gt;</description></item></channel></rss>