<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Variational AutoEncoder | WangJV Blog</title><meta name=keywords content="unsupervised learning,数据生成,VAE"><meta name=description content="1. 动机和推导
对于无监督的样本生成问题，我们之前已经提到过很多次，对于一系列同类型的数据 $\{x_1, x_2, \cdots, x_n\}$，我们假设存在一个理想的分布 $p(x)$，这些数据都是从这个分布中采样得到的。但是想直接学习这个分布非常难。那么是否有可能通过一个足够复杂的神经网络来近似这个理想分布？此外，有一定神经经验的朋友往往有一个信念：“压缩即智能”。那么是否可以先学习一个编码器 $p(z\mid x)$ 将原有的随机向量 $x$ 变换到一个低维的潜空间 $z$，然后再通过一个解码器 $p(x\mid z)$ 将潜空间的向量 $z$ 重新映射回原始空间，从而实现对数据的生成和重构？
变分自编码器（Variational AutoEncoder）就是这个思路的具体实现。显然，通过解码器重建分布 $p(x)$ 可以描述为：
$$
p_\theta(x) = \int p_\theta(x\mid z) p(z) \, dz
$$那么训练 $p_\theta(x)$ 的一个显然的方法是优化其与真实分布 $p(x)$ 之间的 KL 散度：
$$
\theta^* = \arg \min_\theta D_{KL}\bigg(p(x) \| p_\theta(x)\bigg)
$$不妨展开 KL 散度，容易发现：
$$
\begin{aligned}
\theta^*
&= \arg \min_\theta D_{KL}\left(p(x) \| p_\theta(x)\right)\\
&= \arg \min_\theta \bigg\{\mathbb{E}_{x\sim p(x)}\left[\log p(x) \right]- \mathbb{E}_{x\sim p(x)}\left[\log p_\theta(x)\right]\bigg\}
\end{aligned}
$$其中 $\mathbb{E}_{x\sim p(x)}\left[\log p(x) \right]$ 实际上是真实分布 $p(x)$ 的熵，不包含可以优化的参数。可以直接扔掉。那么优化目标可以写作：
$$
\theta^* = \arg \max_\theta \mathbb{E}_{x\sim p(x)}\left[\log p_\theta(x)\right]
$$离散的，对于一批数据 $\{x_1, x_2, \cdots, x_n\}$，我们可以将优化目标改写为："><meta name=author content="WangJV"><link rel=canonical href=https://wangjv0812.cn/2025/10/variational-autoencoder/><link crossorigin=anonymous href=https://wangjv0812.cn/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://wangjv0812.cn/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangjv0812.cn/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangjv0812.cn/favicon-32x32.png><link rel=apple-touch-icon href=https://wangjv0812.cn/apple-touch-icon.png><link rel=mask-icon href=https://wangjv0812.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://wangjv0812.cn/2025/10/variational-autoencoder/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},chtml:{scale:1,minScale:.5,matchFontHeight:!1,displayAlign:"center",displayIndent:"0",mtextInheritFont:!1,merrorInheritFont:!0,mathmlSpacing:!1,skipHtmlTags:["script","noscript","style","textarea","pre","code","a"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"},svg:{scale:1,minScale:.5,mtextInheritFont:!1,merrorInheritFont:!0,mathmlSpacing:!1,skipHtmlTags:["script","noscript","style","textarea","pre","code","a"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"},options:{enableMenu:!0,menuOptions:{settings:{zoom:"Click"}}},loader:{load:["ui/safe","a11y/assistive-mml"]},startup:{ready(){MathJax.startup.defaultReady();const e=new ResizeObserver(e=>{MathJax.typesetPromise()});e.observe(document.body)}}},window.innerWidth<=768&&(MathJax.chtml=MathJax.chtml||{},MathJax.chtml.scale=.9)</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><style>.MathJax{outline:0}@media(max-width:768px){.MathJax{font-size:90%!important}.MathJax_Display{overflow-x:auto;overflow-y:hidden;padding:0!important;margin:1em 0!important}.MathJax_CHTML{line-height:1.2!important}}mjx-container[jax=CHTML][display=true]{overflow-x:auto;overflow-y:hidden;padding:1px 0}</style><meta property="og:url" content="https://wangjv0812.cn/2025/10/variational-autoencoder/"><meta property="og:site_name" content="WangJV Blog"><meta property="og:title" content="Variational AutoEncoder"><meta property="og:description" content="1. 动机和推导 对于无监督的样本生成问题，我们之前已经提到过很多次，对于一系列同类型的数据 $\{x_1, x_2, \cdots, x_n\}$，我们假设存在一个理想的分布 $p(x)$，这些数据都是从这个分布中采样得到的。但是想直接学习这个分布非常难。那么是否有可能通过一个足够复杂的神经网络来近似这个理想分布？此外，有一定神经经验的朋友往往有一个信念：“压缩即智能”。那么是否可以先学习一个编码器 $p(z\mid x)$ 将原有的随机向量 $x$ 变换到一个低维的潜空间 $z$，然后再通过一个解码器 $p(x\mid z)$ 将潜空间的向量 $z$ 重新映射回原始空间，从而实现对数据的生成和重构？
变分自编码器（Variational AutoEncoder）就是这个思路的具体实现。显然，通过解码器重建分布 $p(x)$ 可以描述为：
$$ p_\theta(x) = \int p_\theta(x\mid z) p(z) \, dz $$那么训练 $p_\theta(x)$ 的一个显然的方法是优化其与真实分布 $p(x)$ 之间的 KL 散度：
$$ \theta^* = \arg \min_\theta D_{KL}\bigg(p(x) \| p_\theta(x)\bigg) $$不妨展开 KL 散度，容易发现：
$$ \begin{aligned} \theta^* &= \arg \min_\theta D_{KL}\left(p(x) \| p_\theta(x)\right)\\ &= \arg \min_\theta \bigg\{\mathbb{E}_{x\sim p(x)}\left[\log p(x) \right]- \mathbb{E}_{x\sim p(x)}\left[\log p_\theta(x)\right]\bigg\} \end{aligned} $$其中 $\mathbb{E}_{x\sim p(x)}\left[\log p(x) \right]$ 实际上是真实分布 $p(x)$ 的熵，不包含可以优化的参数。可以直接扔掉。那么优化目标可以写作：
$$ \theta^* = \arg \max_\theta \mathbb{E}_{x\sim p(x)}\left[\log p_\theta(x)\right] $$离散的，对于一批数据 $\{x_1, x_2, \cdots, x_n\}$，我们可以将优化目标改写为："><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-23T21:24:00+08:00"><meta property="article:modified_time" content="2025-10-23T21:24:00+08:00"><meta property="article:tag" content="Unsupervised Learning"><meta property="article:tag" content="数据生成"><meta property="article:tag" content="VAE"><meta property="og:image" content="https://wangjv0812.cn/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://wangjv0812.cn/"><meta name=twitter:title content="Variational AutoEncoder"><meta name=twitter:description content="1. 动机和推导
对于无监督的样本生成问题，我们之前已经提到过很多次，对于一系列同类型的数据 $\{x_1, x_2, \cdots, x_n\}$，我们假设存在一个理想的分布 $p(x)$，这些数据都是从这个分布中采样得到的。但是想直接学习这个分布非常难。那么是否有可能通过一个足够复杂的神经网络来近似这个理想分布？此外，有一定神经经验的朋友往往有一个信念：“压缩即智能”。那么是否可以先学习一个编码器 $p(z\mid x)$ 将原有的随机向量 $x$ 变换到一个低维的潜空间 $z$，然后再通过一个解码器 $p(x\mid z)$ 将潜空间的向量 $z$ 重新映射回原始空间，从而实现对数据的生成和重构？
变分自编码器（Variational AutoEncoder）就是这个思路的具体实现。显然，通过解码器重建分布 $p(x)$ 可以描述为：
$$
p_\theta(x) = \int p_\theta(x\mid z) p(z) \, dz
$$那么训练 $p_\theta(x)$ 的一个显然的方法是优化其与真实分布 $p(x)$ 之间的 KL 散度：
$$
\theta^* = \arg \min_\theta D_{KL}\bigg(p(x) \| p_\theta(x)\bigg)
$$不妨展开 KL 散度，容易发现：
$$
\begin{aligned}
\theta^*
&= \arg \min_\theta D_{KL}\left(p(x) \| p_\theta(x)\right)\\
&= \arg \min_\theta \bigg\{\mathbb{E}_{x\sim p(x)}\left[\log p(x) \right]- \mathbb{E}_{x\sim p(x)}\left[\log p_\theta(x)\right]\bigg\}
\end{aligned}
$$其中 $\mathbb{E}_{x\sim p(x)}\left[\log p(x) \right]$ 实际上是真实分布 $p(x)$ 的熵，不包含可以优化的参数。可以直接扔掉。那么优化目标可以写作：
$$
\theta^* = \arg \max_\theta \mathbb{E}_{x\sim p(x)}\left[\log p_\theta(x)\right]
$$离散的，对于一批数据 $\{x_1, x_2, \cdots, x_n\}$，我们可以将优化目标改写为："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://wangjv0812.cn/posts/"},{"@type":"ListItem","position":2,"name":"Variational AutoEncoder","item":"https://wangjv0812.cn/2025/10/variational-autoencoder/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Variational AutoEncoder","name":"Variational AutoEncoder","description":"1. 动机和推导 对于无监督的样本生成问题，我们之前已经提到过很多次，对于一系列同类型的数据 $\\{x_1, x_2, \\cdots, x_n\\}$，我们假设存在一个理想的分布 $p(x)$，这些数据都是从这个分布中采样得到的。但是想直接学习这个分布非常难。那么是否有可能通过一个足够复杂的神经网络来近似这个理想分布？此外，有一定神经经验的朋友往往有一个信念：“压缩即智能”。那么是否可以先学习一个编码器 $p(z\\mid x)$ 将原有的随机向量 $x$ 变换到一个低维的潜空间 $z$，然后再通过一个解码器 $p(x\\mid z)$ 将潜空间的向量 $z$ 重新映射回原始空间，从而实现对数据的生成和重构？\n变分自编码器（Variational AutoEncoder）就是这个思路的具体实现。显然，通过解码器重建分布 $p(x)$ 可以描述为：\n$$ p_\\theta(x) = \\int p_\\theta(x\\mid z) p(z) \\, dz $$那么训练 $p_\\theta(x)$ 的一个显然的方法是优化其与真实分布 $p(x)$ 之间的 KL 散度：\n$$ \\theta^* = \\arg \\min_\\theta D_{KL}\\bigg(p(x) \\| p_\\theta(x)\\bigg) $$不妨展开 KL 散度，容易发现：\n$$ \\begin{aligned} \\theta^* \u0026= \\arg \\min_\\theta D_{KL}\\left(p(x) \\| p_\\theta(x)\\right)\\\\ \u0026= \\arg \\min_\\theta \\bigg\\{\\mathbb{E}_{x\\sim p(x)}\\left[\\log p(x) \\right]- \\mathbb{E}_{x\\sim p(x)}\\left[\\log p_\\theta(x)\\right]\\bigg\\} \\end{aligned} $$其中 $\\mathbb{E}_{x\\sim p(x)}\\left[\\log p(x) \\right]$ 实际上是真实分布 $p(x)$ 的熵，不包含可以优化的参数。可以直接扔掉。那么优化目标可以写作：\n$$ \\theta^* = \\arg \\max_\\theta \\mathbb{E}_{x\\sim p(x)}\\left[\\log p_\\theta(x)\\right] $$离散的，对于一批数据 $\\{x_1, x_2, \\cdots, x_n\\}$，我们可以将优化目标改写为：\n","keywords":["unsupervised learning","数据生成","VAE"],"articleBody":"1. 动机和推导 对于无监督的样本生成问题，我们之前已经提到过很多次，对于一系列同类型的数据 $\\{x_1, x_2, \\cdots, x_n\\}$，我们假设存在一个理想的分布 $p(x)$，这些数据都是从这个分布中采样得到的。但是想直接学习这个分布非常难。那么是否有可能通过一个足够复杂的神经网络来近似这个理想分布？此外，有一定神经经验的朋友往往有一个信念：“压缩即智能”。那么是否可以先学习一个编码器 $p(z\\mid x)$ 将原有的随机向量 $x$ 变换到一个低维的潜空间 $z$，然后再通过一个解码器 $p(x\\mid z)$ 将潜空间的向量 $z$ 重新映射回原始空间，从而实现对数据的生成和重构？\n变分自编码器（Variational AutoEncoder）就是这个思路的具体实现。显然，通过解码器重建分布 $p(x)$ 可以描述为：\n$$ p_\\theta(x) = \\int p_\\theta(x\\mid z) p(z) \\, dz $$那么训练 $p_\\theta(x)$ 的一个显然的方法是优化其与真实分布 $p(x)$ 之间的 KL 散度：\n$$ \\theta^* = \\arg \\min_\\theta D_{KL}\\bigg(p(x) \\| p_\\theta(x)\\bigg) $$不妨展开 KL 散度，容易发现：\n$$ \\begin{aligned} \\theta^* \u0026= \\arg \\min_\\theta D_{KL}\\left(p(x) \\| p_\\theta(x)\\right)\\\\ \u0026= \\arg \\min_\\theta \\bigg\\{\\mathbb{E}_{x\\sim p(x)}\\left[\\log p(x) \\right]- \\mathbb{E}_{x\\sim p(x)}\\left[\\log p_\\theta(x)\\right]\\bigg\\} \\end{aligned} $$其中 $\\mathbb{E}_{x\\sim p(x)}\\left[\\log p(x) \\right]$ 实际上是真实分布 $p(x)$ 的熵，不包含可以优化的参数。可以直接扔掉。那么优化目标可以写作：\n$$ \\theta^* = \\arg \\max_\\theta \\mathbb{E}_{x\\sim p(x)}\\left[\\log p_\\theta(x)\\right] $$离散的，对于一批数据 $\\{x_1, x_2, \\cdots, x_n\\}$，我们可以将优化目标改写为：\n$$ \\theta^* = \\arg \\max_\\theta \\frac{1}{n}\\sum_{i=1}^n \\log p_\\theta(x_i) $$但是此时，计算 $\\log p_\\theta(x_i)$ 仍然是一个难点。不妨将 $\\log p_\\theta(x_i)$ 的形式展开，有：\n$$ \\log p_\\theta(x_i) = \\log \\int p_\\theta(x_i, z) \\, dz $$想直接计算这个积分几乎是不可能的，一个显然的思路是 Monto Carlo 积分，将这个积分的形式转换为一个可以对随机变量有效采样的期望的形式，通过不断对随机变量采样，就可以很容易的计算出积分的结果了。\n盯着这个式子，不难发现，既然是对 $z$ 做积分，那么这个期望所依赖的随机变量一定是关于 $z$ 的。此时有两个选择，要么直接使用 $p(z)$，要么使用编码器 $p_\\psi(z\\mid x_i)$。如果选择 $p(z)$，那么上面的形式可以写成：\n$$ \\begin{aligned} \\log p_\\theta(x_i) \u0026= \\log \\int p_\\theta(x_i, z) \\, dz\\\\ \u0026= \\log \\mathbb{E}_{z\\sim p(z)}\\left[p_\\theta(x_i \\mid z)\\right] \\end{aligned} $$这相当于希望训练出一个 “过于强大” 的编码。希望训练出一个从任意的 $z$ 到 $x$ 的映射。我们抛弃了编码器带来的，从数据 $x_i$ 到 $z_i$ 之间的信息。如果直接这样训练，会导致 $z_i$ 到 $x_i$ 的映射是完全随机的，模型无法学习到一个稳定、连续且有意义的映射关系。因此我们选择使用编码器 $p_\\psi(z\\mid x_i)$ 来构造期望，保留一些从数据 $x_i$ 到潜变量 $z$ 的信息。那么上面的形式可以写成：\n$$ \\begin{aligned} \\log p_\\theta(x_i) \u0026= \\log \\int p_\\theta(x_i, z) \\, dz\\\\ \u0026= \\log \\int p_\\psi(z \\mid x_i) \\frac{p_\\theta(x_i, z)}{p_\\psi(z \\mid x_i)} \\, dz\\\\ \u0026= \\log \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)}\\left[\\frac{p_\\theta(x_i, z)}{p_\\psi(z \\mid x_i)}\\right] \\end{aligned} $$我们知道，$\\log$ 是一个凹函数，而期望算子本质上是一个加性操作。那根据 Jensen 不等式，有：\n$$ \\begin{aligned} \\log p_\\theta(x_i) \u0026= \\log \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)}\\left[\\frac{p_\\theta(x_i, z)}{p_\\psi(z \\mid x_i)}\\right]\\\\ \u0026\\geq \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)}\\left[\\log \\frac{p_\\theta(x_i, z)}{p_\\psi(z \\mid x_i)}\\right]\\\\ \u0026= \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)}\\bigg[\\log p_\\theta(x_i \\mid z) + \\log p(z) - \\log p_\\psi(z \\mid x_i)\\bigg]\\\\ \u0026= \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log p_\\theta(x_i \\mid z)\\bigg] - \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log \\frac{p_\\psi(z \\mid x_i)}{p(z)}\\bigg]\\\\ \u0026= \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log p_\\theta(x_i \\mid z)\\bigg] - D_{KL}\\bigg(p_\\psi(z \\mid x_i) \\| p(z)\\bigg) \\end{aligned} $$这个形式事实上就是 ELBO（Evidence Lower Bound）的形式。对于上面这个形式，我们做这样的理解：\n$$ \\begin{array}{ll} \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log p_\\theta(x_i \\mid z)\\bigg]\u0026 重构项\\\\ D_{KL}\\bigg(p_\\psi(z \\mid x_i) \\| p(z)\\bigg)\u0026 KL 散度项\\\\ \\end{array} $$2. 工程实践 VAE 假设潜变量层的先验分布 $p(z)$ 是一个高斯分布 $\\mathcal{N}(0, I)$，那么一个合理的假设是编码器 $p_\\psi(z\\mid x)$ 必然很接近于高斯分布，不妨将其建设为一个高斯分布族。此外为了方便处理，不妨同样认定解码器 $p_\\theta(x\\mid z)$ 也是一个高斯分布族。那么在工程上我们可以做这样的处理：\n对于编码器，我们使用一个神经网络，输入数据 $x$，输出高斯分布族 $p(z\\mid x)$ 的均值 $\\mu_\\psi(x)$ 和方差 $\\sigma_\\psi(x)$。 对于解码器，我们使用一个神经网络，输入潜变量 $z$，输出高斯分布族 $p(x\\mid z)$ 的均值 $\\mu_\\theta(z)$ 和方差 $\\sigma_\\theta(z)$。 那么对于第一项，重构项可以写作：\n$$ \\begin{aligned} \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log p_\\theta(x_i \\mid z)\\bigg] \u0026= \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log \\mathcal{N}(x_i \\mid \\mu_\\theta(z), \\sigma_\\theta(z))\\bigg]\\\\ \u0026\\sim - \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log \\sigma_\\theta(z)\\bigg] - \\frac{1}{2}\\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\frac{(x_i - \\mu_\\theta(z))^2}{\\sigma_\\theta(z)^2}\\bigg] \\end{aligned} $$对于 KL 散度项，由于 Gaussian 分布的 KL 散度有一个解析解，因此可以直接写作：\n$$ \\begin{aligned} D_{KL}\\bigg(p_\\psi(z \\mid x_i) \\| p(z)\\bigg) \u0026= D_{KL}\\bigg(\\mathcal{N}(\\mu_\\psi(x_i), \\sigma_\\psi(x_i)) \\| \\mathcal{N}(0, I)\\bigg)\\\\ \u0026= \\frac{1}{2} \\sum_{j=1}^d \\left( \\sigma_\\psi(x_i)_j^2 + \\mu_\\psi(x_i)_j^2 - 1 - \\log \\sigma_\\psi(x_i)_j^2 \\right) \\end{aligned} $$最终的 Loss 形式可以写作：\n$$ \\begin{aligned} L_{VAE}(x_i) \u0026=\\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log p_\\theta(x_i \\mid z)\\bigg] - D_{KL}\\bigg(p_\\psi(z \\mid x_i) \\| p(z)\\bigg)\\\\ \u0026\\sim - \\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log \\sigma_\\theta(z)\\bigg]- \\frac{1}{2}\\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\frac{(x_i - \\mu_\\theta(z))^2}{\\sigma_\\theta(z)^2}\\bigg] - \\frac{1}{2} \\sum_{j=1}^d \\left( \\sigma_\\ psi(x_i)_j^2 + \\mu_\\psi(x_i)_j^2 - 1 - \\log \\sigma_\\psi(x_i)_j^2 \\right) \\end{aligned} $$对这个形式吗，我们有一个直观的理解：\n$\\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\log \\sigma_\\theta(z)\\bigg]$ 是一个正则化项，鼓励模型尽可能的缩小预测出的协方差的大小，让解码器预测出的结果更加确定。 $\\frac{1}{2}\\mathbb{E}_{z\\sim p_\\psi(z\\mid x_i)} \\bigg[\\frac{(x_i - \\mu_\\theta(z))^2}{\\sigma_\\theta(z)^2}\\bigg]$ 是一个由不确定性 （$\\sigma$） 加权的重构误差，事实上就是一个 MLE。 $D_{KL}\\bigg(p_\\psi(z \\mid x_i) \\| p(z)\\bigg)$ 也是一个正则化项，它鼓励模型尽可能的贴近高斯分布。具体为什么要这样我们后续会讨论。 此时，算法流程是这样的：\n从数据集中任选一个样本 $x_i$ 通过编码器，计算出一组潜变量的分布参数 $\\mu_\\psi(x_i), \\sigma_\\psi(x_i)$ 根据 $\\mu_\\psi(x_i), \\sigma_\\psi(x_i)$ 我们可以直接计算出 KL 散度项 同样根据 $\\mu_\\psi(x_i), \\sigma_\\psi(x_i)$，我们获得了期望所依赖的分布 $p_\\psi(z\\mid x) \\sim \\mathcal N(\\mu_\\psi(x_i), \\sigma_\\psi(x_i))$。 对 $\\mathcal N(\\mu_\\psi(x_i), \\sigma_\\psi(x_i))$ 采样，即可计算出重构项 计算 Loss，更新参数 3. 讨论 要理解 VAE 为什么要这样设计，需要先理解此前 AutoEncoder 面对着什么问题:\nAutoEncoder 训练常常面临学习出恒等映射这个问题，即编码器和解码器并没有学习到任何有意义的对数据的压缩和重构，而是简单的将对应关系记忆了下来。 我们希望 Encoder 学习到的浅变量之间是连续、稠密且可插值的，但是模型往往不随人所愿。对于模型而言，最省事的方法是将不同模式之间的浅变量尽可能的拉远避免混淆，不同模式的浅变量之间就出现了很多无意义的空隙，导致差值毫无意义。 为了解决第一个问题，我们并不直接将 Encoder 的输出交给 Decoder 来解码，而是让 Encoder 输出一个分布，之后在这个分布中做一次采样，将采样交给 Decoder 来解码。这样从根本上杜绝了学习恒等映射的可能性。\n更为巧妙的是 VAE 同样很好的解决了第二个问题。我们不妨思考一下，如果去掉 KL 散度项会怎样？事实上模型会天然的将 Latent Space 的协方差渐小，消除不确定性，这样预测的结果会更加简单确定。由此退化为一个经典的 AE。那么此时不同模式的浅变量层之间的空隙会变大，差值效果就会很差。KL 散度项事实上强制保证了 Latent Space 具有足够的随机性（协方差接近 I），同时还保证 Latent Space 分布的均值还得足够 “稠密” 的分布在原点附近。这个方法强迫模型学习到一个连续、稠密且可插值的 Latent Space，从而保证了差值的有效性和学习的效率。时是上，VAE 中的 Variational 正是指的这种通过 KL 散度来正则化潜变量分布的思想。\nReferences ","wordCount":"537","inLanguage":"en","image":"https://wangjv0812.cn/","datePublished":"2025-10-23T21:24:00+08:00","dateModified":"2025-10-23T21:24:00+08:00","author":{"@type":"Person","name":"WangJV"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://wangjv0812.cn/2025/10/variational-autoencoder/"},"publisher":{"@type":"Organization","name":"WangJV Blog","logo":{"@type":"ImageObject","url":"https://wangjv0812.cn/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangjv0812.cn/ accesskey=h title="WangJV Blog (Alt + H)">WangJV Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangjv0812.cn/ title=Home><span>Home</span></a></li><li><a href=https://wangjv0812.cn/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://wangjv0812.cn/resources/ title=Resources><span>Resources</span></a></li><li><a href=https://wangjv0812.cn/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://wangjv0812.cn/search/ title="🔍 Search (Alt + /)" accesskey=/><span>🔍 Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://wangjv0812.cn/>Home</a>&nbsp;»&nbsp;<a href=https://wangjv0812.cn/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Variational AutoEncoder</h1><div class=post-meta><span title='2025-10-23 21:24:00 +0800 +0800'>October 23, 2025</span>&nbsp;·&nbsp;WangJV&nbsp;|&nbsp;<a href=https://github.com/WangJV0812/WangJV-Blog-Source/tree/master/content/posts/Variational%20Auto%20Encoder/index.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-动机和推导>1. 动机和推导</a></li><li><a href=#2-工程实践>2. 工程实践</a></li><li><a href=#3-讨论>3. 讨论</a></li><li><a href=#references>References</a></li></ul></nav></div></details></div><div class=post-content><h2 id=1-动机和推导>1. 动机和推导<a hidden class=anchor aria-hidden=true href=#1-动机和推导>#</a></h2><p>对于无监督的样本生成问题，我们之前已经提到过很多次，对于一系列同类型的数据 $\{x_1, x_2, \cdots, x_n\}$，我们假设存在一个理想的分布 $p(x)$，这些数据都是从这个分布中采样得到的。但是想直接学习这个分布非常难。那么是否有可能通过一个足够复杂的神经网络来近似这个理想分布？此外，有一定神经经验的朋友往往有一个信念：“<em>压缩即智能</em>”。那么是否可以先学习一个编码器 $p(z\mid x)$ 将原有的随机向量 $x$ 变换到一个低维的潜空间 $z$，然后再通过一个解码器 $p(x\mid z)$ 将潜空间的向量 $z$ 重新映射回原始空间，从而实现对数据的生成和重构？</p><p>变分自编码器（Variational AutoEncoder）就是这个思路的具体实现。显然，通过解码器重建分布 $p(x)$ 可以描述为：</p>$$
p_\theta(x) = \int p_\theta(x\mid z) p(z) \, dz
$$<p>那么训练 $p_\theta(x)$ 的一个显然的方法是优化其与真实分布 $p(x)$ 之间的 KL 散度：</p>$$
\theta^* = \arg \min_\theta D_{KL}\bigg(p(x) \| p_\theta(x)\bigg)
$$<p>不妨展开 KL 散度，容易发现：</p>$$
\begin{aligned}
\theta^*
&= \arg \min_\theta D_{KL}\left(p(x) \| p_\theta(x)\right)\\
&= \arg \min_\theta \bigg\{\mathbb{E}_{x\sim p(x)}\left[\log p(x) \right]- \mathbb{E}_{x\sim p(x)}\left[\log p_\theta(x)\right]\bigg\}
\end{aligned}
$$<p>其中 $\mathbb{E}_{x\sim p(x)}\left[\log p(x) \right]$ 实际上是真实分布 $p(x)$ 的熵，不包含可以优化的参数。可以直接扔掉。那么优化目标可以写作：</p>$$
\theta^* = \arg \max_\theta \mathbb{E}_{x\sim p(x)}\left[\log p_\theta(x)\right]
$$<p>离散的，对于一批数据 $\{x_1, x_2, \cdots, x_n\}$，我们可以将优化目标改写为：</p>$$
\theta^* = \arg \max_\theta \frac{1}{n}\sum_{i=1}^n \log p_\theta(x_i)
$$<p>但是此时，计算 $\log p_\theta(x_i)$ 仍然是一个难点。不妨将 $\log p_\theta(x_i)$ 的形式展开，有：</p>$$
\log p_\theta(x_i) = \log \int p_\theta(x_i, z) \, dz
$$<p>想直接计算这个积分几乎是不可能的，一个显然的思路是 Monto Carlo 积分，将这个积分的形式转换为一个可以对随机变量有效采样的期望的形式，通过不断对随机变量采样，就可以很容易的计算出积分的结果了。</p><p>盯着这个式子，不难发现，既然是对 $z$ 做积分，那么这个期望所依赖的随机变量一定是关于 $z$ 的。此时有两个选择，要么直接使用 $p(z)$，要么使用编码器 $p_\psi(z\mid x_i)$。如果选择 $p(z)$，那么上面的形式可以写成：</p>$$
\begin{aligned}
\log p_\theta(x_i)
&= \log \int p_\theta(x_i, z) \, dz\\
&= \log \mathbb{E}_{z\sim p(z)}\left[p_\theta(x_i \mid z)\right]
\end{aligned}
$$<p>这相当于希望训练出一个 “过于强大” 的编码。希望训练出一个从任意的 $z$ 到 $x$ 的映射。我们抛弃了编码器带来的，从数据 $x_i$ 到 $z_i$ 之间的信息。如果直接这样训练，会导致 $z_i$ 到 $x_i$ 的映射是完全随机的，模型无法学习到一个稳定、连续且有意义的映射关系。因此我们选择使用编码器 $p_\psi(z\mid x_i)$ 来构造期望，保留一些从数据 $x_i$ 到潜变量 $z$ 的信息。那么上面的形式可以写成：</p>$$
\begin{aligned}
\log p_\theta(x_i)
&= \log \int p_\theta(x_i, z) \, dz\\
&= \log \int p_\psi(z \mid x_i) \frac{p_\theta(x_i, z)}{p_\psi(z \mid x_i)} \, dz\\
&= \log \mathbb{E}_{z\sim p_\psi(z\mid x_i)}\left[\frac{p_\theta(x_i, z)}{p_\psi(z \mid x_i)}\right]
\end{aligned}
$$<p>我们知道，$\log$ 是一个凹函数，而期望算子本质上是一个加性操作。那根据 Jensen 不等式，有：</p>$$
\begin{aligned}
\log p_\theta(x_i)
&= \log \mathbb{E}_{z\sim p_\psi(z\mid x_i)}\left[\frac{p_\theta(x_i, z)}{p_\psi(z \mid x_i)}\right]\\
&\geq \mathbb{E}_{z\sim p_\psi(z\mid x_i)}\left[\log \frac{p_\theta(x_i, z)}{p_\psi(z \mid x_i)}\right]\\
&= \mathbb{E}_{z\sim p_\psi(z\mid x_i)}\bigg[\log p_\theta(x_i \mid z) + \log p(z) - \log p_\psi(z \mid x_i)\bigg]\\
&= \mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log p_\theta(x_i \mid z)\bigg] - \mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log \frac{p_\psi(z \mid x_i)}{p(z)}\bigg]\\
&= \mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log p_\theta(x_i \mid z)\bigg] - D_{KL}\bigg(p_\psi(z \mid x_i) \| p(z)\bigg)
\end{aligned}
$$<p>这个形式事实上就是 ELBO（Evidence Lower Bound）的形式。对于上面这个形式，我们做这样的理解：</p>$$
\begin{array}{ll}
\mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log p_\theta(x_i \mid z)\bigg]& 重构项\\
D_{KL}\bigg(p_\psi(z \mid x_i) \| p(z)\bigg)& KL 散度项\\
\end{array}
$$<h2 id=2-工程实践>2. 工程实践<a hidden class=anchor aria-hidden=true href=#2-工程实践>#</a></h2><p>VAE 假设潜变量层的先验分布 $p(z)$ 是一个高斯分布 $\mathcal{N}(0, I)$，那么一个合理的假设是编码器 $p_\psi(z\mid x)$ 必然很接近于高斯分布，不妨将其建设为一个高斯分布族。此外为了方便处理，不妨同样认定解码器 $p_\theta(x\mid z)$ 也是一个高斯分布族。那么在工程上我们可以做这样的处理：</p><ol><li>对于编码器，我们使用一个神经网络，输入数据 $x$，输出高斯分布族 $p(z\mid x)$ 的均值 $\mu_\psi(x)$ 和方差 $\sigma_\psi(x)$。</li><li>对于解码器，我们使用一个神经网络，输入潜变量 $z$，输出高斯分布族 $p(x\mid z)$ 的均值 $\mu_\theta(z)$ 和方差 $\sigma_\theta(z)$。</li></ol><p>那么对于第一项，重构项可以写作：</p>$$
\begin{aligned}
\mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log p_\theta(x_i \mid z)\bigg]
&= \mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log \mathcal{N}(x_i \mid \mu_\theta(z), \sigma_\theta(z))\bigg]\\
&\sim - \mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log \sigma_\theta(z)\bigg] - \frac{1}{2}\mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\frac{(x_i - \mu_\theta(z))^2}{\sigma_\theta(z)^2}\bigg]
\end{aligned}
$$<p>对于 KL 散度项，由于 Gaussian 分布的 KL 散度有一个解析解，因此可以直接写作：</p>$$
\begin{aligned}
D_{KL}\bigg(p_\psi(z \mid x_i) \| p(z)\bigg)
&= D_{KL}\bigg(\mathcal{N}(\mu_\psi(x_i), \sigma_\psi(x_i)) \| \mathcal{N}(0, I)\bigg)\\
&= \frac{1}{2} \sum_{j=1}^d \left( \sigma_\psi(x_i)_j^2 + \mu_\psi(x_i)_j^2 - 1 - \log \sigma_\psi(x_i)_j^2 \right)
\end{aligned}
$$<p>最终的 Loss 形式可以写作：</p>$$
\begin{aligned}
L_{VAE}(x_i)
&=\mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log p_\theta(x_i \mid z)\bigg] - D_{KL}\bigg(p_\psi(z \mid x_i) \| p(z)\bigg)\\
&\sim - \mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log \sigma_\theta(z)\bigg]- \frac{1}{2}\mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\frac{(x_i - \mu_\theta(z))^2}{\sigma_\theta(z)^2}\bigg] - \frac{1}{2} \sum_{j=1}^d \left( \sigma_\ psi(x_i)_j^2 + \mu_\psi(x_i)_j^2 - 1 - \log \sigma_\psi(x_i)_j^2 \right)
\end{aligned}
$$<p>对这个形式吗，我们有一个直观的理解：</p><ol><li>$\mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\log \sigma_\theta(z)\bigg]$ 是一个正则化项，鼓励模型尽可能的缩小预测出的协方差的大小，让解码器预测出的结果更加确定。</li><li>$\frac{1}{2}\mathbb{E}_{z\sim p_\psi(z\mid x_i)} \bigg[\frac{(x_i - \mu_\theta(z))^2}{\sigma_\theta(z)^2}\bigg]$ 是一个由不确定性 （$\sigma$） 加权的重构误差，事实上就是一个 MLE。</li><li>$D_{KL}\bigg(p_\psi(z \mid x_i) \| p(z)\bigg)$ 也是一个正则化项，它鼓励模型尽可能的贴近高斯分布。具体为什么要这样我们后续会讨论。</li></ol><p>此时，算法流程是这样的：</p><ol><li>从数据集中任选一个样本 $x_i$</li><li>通过编码器，计算出一组潜变量的分布参数 $\mu_\psi(x_i), \sigma_\psi(x_i)$</li><li>根据 $\mu_\psi(x_i), \sigma_\psi(x_i)$ 我们可以直接计算出 KL 散度项</li><li>同样根据 $\mu_\psi(x_i), \sigma_\psi(x_i)$，我们获得了期望所依赖的分布 $p_\psi(z\mid x) \sim \mathcal N(\mu_\psi(x_i), \sigma_\psi(x_i))$。</li><li>对 $\mathcal N(\mu_\psi(x_i), \sigma_\psi(x_i))$ 采样，即可计算出重构项</li><li>计算 Loss，更新参数</li></ol><h2 id=3-讨论>3. 讨论<a hidden class=anchor aria-hidden=true href=#3-讨论>#</a></h2><p>要理解 VAE 为什么要这样设计，需要先理解此前 AutoEncoder 面对着什么问题:</p><ol><li>AutoEncoder 训练常常面临学习出恒等映射这个问题，即编码器和解码器并没有学习到任何有意义的对数据的压缩和重构，而是简单的将对应关系记忆了下来。</li><li>我们希望 Encoder 学习到的浅变量之间是连续、稠密且可插值的，但是模型往往不随人所愿。对于模型而言，最省事的方法是将不同模式之间的浅变量尽可能的拉远避免混淆，不同模式的浅变量之间就出现了很多无意义的空隙，导致差值毫无意义。</li></ol><p>为了解决第一个问题，我们并不直接将 Encoder 的输出交给 Decoder 来解码，而是让 Encoder 输出一个分布，之后在这个分布中做一次采样，将采样交给 Decoder 来解码。这样从根本上杜绝了学习恒等映射的可能性。</p><p>更为巧妙的是 VAE 同样很好的解决了第二个问题。我们不妨思考一下，如果去掉 KL 散度项会怎样？事实上模型会天然的将 Latent Space 的协方差渐小，消除不确定性，这样预测的结果会更加简单确定。由此退化为一个经典的 AE。那么此时不同模式的浅变量层之间的空隙会变大，差值效果就会很差。KL 散度项事实上强制保证了 Latent Space 具有足够的随机性（协方差接近 I），同时还保证 Latent Space 分布的均值还得足够 “稠密” 的分布在原点附近。这个方法强迫模型学习到一个连续、稠密且可插值的 Latent Space，从而保证了差值的有效性和学习的效率。时是上，VAE 中的 Variational 正是指的这种通过 KL 散度来正则化潜变量分布的思想。</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2></div><footer class=post-footer><ul class=post-tags><li><a href=https://wangjv0812.cn/tags/unsupervised-learning/>Unsupervised Learning</a></li><li><a href=https://wangjv0812.cn/tags/%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/>数据生成</a></li><li><a href=https://wangjv0812.cn/tags/vae/>VAE</a></li></ul><nav class=paginav><a class=next href=https://wangjv0812.cn/2025/10/denoising-score-matching/><span class=title>Next »</span><br><span>Denoising Score Matching</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://wangjv0812.cn/>WangJV Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>