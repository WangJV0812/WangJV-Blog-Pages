<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Variational Bayesian Inference | WangJV Blog</title><meta name=keywords content="Variational Inference,Bayesian Inference,KL Divergence,ELBO"><meta name=description content="1. 动机
对于一个状态 $x$，在通过传感器进行一次观测 $y$ 后，我们希望可以计算出后验分布 $p(x\mid y)$，即在观测到 $y$ 的情况下，状态 $x$ 的分布。为了计算后验分布的形式，我们可以使用贝叶斯公式：
$$
\begin{aligned}
p(x\mid y)
&= \frac{p(y\mid x) p(x)}{p(y)}\\
&= \frac{p(y\mid x) p(x)}{\int p(y\mid x) p(x) \mathrm{d}x}
\end{aligned}
$$对于状态估计问题，我们只需要找到使得 $p(x\mid y)$ 最大的状态 $x$。 由于 $p(y)$ 是一个常数，我们可以将其忽略，只需要最大化分子部分。但是一些应用场景中，还需要我们计算出具体的后验分布的形式。但是这往往非常的难，边缘似然 $p(y)$ 的计算往往是几乎不可能的。因此一个或许可行的办法是，使用一个相对简单的分布 $q(x)$ 代替后验分布。那么原本的贝叶斯问题变成一个变分优化问题，不妨用 KL 散度衡量差异。
2. KL 散度的不对称性
但是一个很核心的问题是，KL 散度不具有对称性，$D_{KL}(p\| q) \neq D_{KL}(q\| p)$，在实际操作中，我们应该如何选择？不妨先观察这两个对称的 KL 散度的具体形式：
$$
\begin{aligned}
D_{KL}(p \| q)
&= -\int p(x\mid y) \log \frac{q(x)}{p(x\mid y)} \mathrm{d}x\\
&= -\int p(x\mid y) \log q(x) \mathrm{d}x + \int p(x\mid y) \log p(x\mid y) \mathrm{d}x
\end{aligned}
$$其中，$\int p(x\mid y) \log q(x) \mathrm{d}x$ 实质上是 $p$ 与 $q$ 之间的交叉熵，不妨定义 $H(p, q) = \int p(x\mid y) \log q(x) \mathrm{d}x$。而 $\int p(x\mid y) \log p(x\mid y) \mathrm{d}x$ 则是关于 $p$ 的熵。$p$ 的熵实质上是一个常数，因此实质上："><meta name=author content="WangJV"><link rel=canonical href=https://wangjv0812.cn/2025/10/variational-bayesian-inference/><link crossorigin=anonymous href=https://wangjv0812.cn/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://wangjv0812.cn/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangjv0812.cn/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangjv0812.cn/favicon-32x32.png><link rel=apple-touch-icon href=https://wangjv0812.cn/apple-touch-icon.png><link rel=mask-icon href=https://wangjv0812.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://wangjv0812.cn/2025/10/variational-bayesian-inference/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},chtml:{scale:1,minScale:.5,matchFontHeight:!1,displayAlign:"center",displayIndent:"0",mtextInheritFont:!1,merrorInheritFont:!0,mathmlSpacing:!1,skipHtmlTags:["script","noscript","style","textarea","pre","code","a"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"},svg:{scale:1,minScale:.5,mtextInheritFont:!1,merrorInheritFont:!0,mathmlSpacing:!1,skipHtmlTags:["script","noscript","style","textarea","pre","code","a"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"},options:{enableMenu:!0,menuOptions:{settings:{zoom:"Click"}}},loader:{load:["ui/safe","a11y/assistive-mml"]},startup:{ready(){MathJax.startup.defaultReady();const e=new ResizeObserver(e=>{MathJax.typesetPromise()});e.observe(document.body)}}},window.innerWidth<=768&&(MathJax.chtml=MathJax.chtml||{},MathJax.chtml.scale=.9)</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><style>.MathJax{outline:0}@media(max-width:768px){.MathJax{font-size:90%!important}.MathJax_Display{overflow-x:auto;overflow-y:hidden;padding:0!important;margin:1em 0!important}.MathJax_CHTML{line-height:1.2!important}}mjx-container[jax=CHTML][display=true]{overflow-x:auto;overflow-y:hidden;padding:1px 0}</style><meta property="og:url" content="https://wangjv0812.cn/2025/10/variational-bayesian-inference/"><meta property="og:site_name" content="WangJV Blog"><meta property="og:title" content="Variational Bayesian Inference"><meta property="og:description" content="1. 动机 对于一个状态 $x$，在通过传感器进行一次观测 $y$ 后，我们希望可以计算出后验分布 $p(x\mid y)$，即在观测到 $y$ 的情况下，状态 $x$ 的分布。为了计算后验分布的形式，我们可以使用贝叶斯公式：
$$ \begin{aligned} p(x\mid y) &= \frac{p(y\mid x) p(x)}{p(y)}\\ &= \frac{p(y\mid x) p(x)}{\int p(y\mid x) p(x) \mathrm{d}x} \end{aligned} $$对于状态估计问题，我们只需要找到使得 $p(x\mid y)$ 最大的状态 $x$。 由于 $p(y)$ 是一个常数，我们可以将其忽略，只需要最大化分子部分。但是一些应用场景中，还需要我们计算出具体的后验分布的形式。但是这往往非常的难，边缘似然 $p(y)$ 的计算往往是几乎不可能的。因此一个或许可行的办法是，使用一个相对简单的分布 $q(x)$ 代替后验分布。那么原本的贝叶斯问题变成一个变分优化问题，不妨用 KL 散度衡量差异。
2. KL 散度的不对称性 但是一个很核心的问题是，KL 散度不具有对称性，$D_{KL}(p\| q) \neq D_{KL}(q\| p)$，在实际操作中，我们应该如何选择？不妨先观察这两个对称的 KL 散度的具体形式：
$$ \begin{aligned} D_{KL}(p \| q) &= -\int p(x\mid y) \log \frac{q(x)}{p(x\mid y)} \mathrm{d}x\\ &= -\int p(x\mid y) \log q(x) \mathrm{d}x + \int p(x\mid y) \log p(x\mid y) \mathrm{d}x \end{aligned} $$其中，$\int p(x\mid y) \log q(x) \mathrm{d}x$ 实质上是 $p$ 与 $q$ 之间的交叉熵，不妨定义 $H(p, q) = \int p(x\mid y) \log q(x) \mathrm{d}x$。而 $\int p(x\mid y) \log p(x\mid y) \mathrm{d}x$ 则是关于 $p$ 的熵。$p$ 的熵实质上是一个常数，因此实质上："><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-28T23:35:25+08:00"><meta property="article:modified_time" content="2025-10-28T23:35:25+08:00"><meta property="article:tag" content="Variational Inference"><meta property="article:tag" content="Bayesian Inference"><meta property="article:tag" content="KL Divergence"><meta property="article:tag" content="ELBO"><meta property="og:image" content="https://wangjv0812.cn/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://wangjv0812.cn/"><meta name=twitter:title content="Variational Bayesian Inference"><meta name=twitter:description content="1. 动机
对于一个状态 $x$，在通过传感器进行一次观测 $y$ 后，我们希望可以计算出后验分布 $p(x\mid y)$，即在观测到 $y$ 的情况下，状态 $x$ 的分布。为了计算后验分布的形式，我们可以使用贝叶斯公式：
$$
\begin{aligned}
p(x\mid y)
&= \frac{p(y\mid x) p(x)}{p(y)}\\
&= \frac{p(y\mid x) p(x)}{\int p(y\mid x) p(x) \mathrm{d}x}
\end{aligned}
$$对于状态估计问题，我们只需要找到使得 $p(x\mid y)$ 最大的状态 $x$。 由于 $p(y)$ 是一个常数，我们可以将其忽略，只需要最大化分子部分。但是一些应用场景中，还需要我们计算出具体的后验分布的形式。但是这往往非常的难，边缘似然 $p(y)$ 的计算往往是几乎不可能的。因此一个或许可行的办法是，使用一个相对简单的分布 $q(x)$ 代替后验分布。那么原本的贝叶斯问题变成一个变分优化问题，不妨用 KL 散度衡量差异。
2. KL 散度的不对称性
但是一个很核心的问题是，KL 散度不具有对称性，$D_{KL}(p\| q) \neq D_{KL}(q\| p)$，在实际操作中，我们应该如何选择？不妨先观察这两个对称的 KL 散度的具体形式：
$$
\begin{aligned}
D_{KL}(p \| q)
&= -\int p(x\mid y) \log \frac{q(x)}{p(x\mid y)} \mathrm{d}x\\
&= -\int p(x\mid y) \log q(x) \mathrm{d}x + \int p(x\mid y) \log p(x\mid y) \mathrm{d}x
\end{aligned}
$$其中，$\int p(x\mid y) \log q(x) \mathrm{d}x$ 实质上是 $p$ 与 $q$ 之间的交叉熵，不妨定义 $H(p, q) = \int p(x\mid y) \log q(x) \mathrm{d}x$。而 $\int p(x\mid y) \log p(x\mid y) \mathrm{d}x$ 则是关于 $p$ 的熵。$p$ 的熵实质上是一个常数，因此实质上："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://wangjv0812.cn/posts/"},{"@type":"ListItem","position":2,"name":"Variational Bayesian Inference","item":"https://wangjv0812.cn/2025/10/variational-bayesian-inference/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Variational Bayesian Inference","name":"Variational Bayesian Inference","description":"1. 动机 对于一个状态 $x$，在通过传感器进行一次观测 $y$ 后，我们希望可以计算出后验分布 $p(x\\mid y)$，即在观测到 $y$ 的情况下，状态 $x$ 的分布。为了计算后验分布的形式，我们可以使用贝叶斯公式：\n$$ \\begin{aligned} p(x\\mid y) \u0026= \\frac{p(y\\mid x) p(x)}{p(y)}\\\\ \u0026= \\frac{p(y\\mid x) p(x)}{\\int p(y\\mid x) p(x) \\mathrm{d}x} \\end{aligned} $$对于状态估计问题，我们只需要找到使得 $p(x\\mid y)$ 最大的状态 $x$。 由于 $p(y)$ 是一个常数，我们可以将其忽略，只需要最大化分子部分。但是一些应用场景中，还需要我们计算出具体的后验分布的形式。但是这往往非常的难，边缘似然 $p(y)$ 的计算往往是几乎不可能的。因此一个或许可行的办法是，使用一个相对简单的分布 $q(x)$ 代替后验分布。那么原本的贝叶斯问题变成一个变分优化问题，不妨用 KL 散度衡量差异。\n2. KL 散度的不对称性 但是一个很核心的问题是，KL 散度不具有对称性，$D_{KL}(p\\| q) \\neq D_{KL}(q\\| p)$，在实际操作中，我们应该如何选择？不妨先观察这两个对称的 KL 散度的具体形式：\n$$ \\begin{aligned} D_{KL}(p \\| q) \u0026= -\\int p(x\\mid y) \\log \\frac{q(x)}{p(x\\mid y)} \\mathrm{d}x\\\\ \u0026= -\\int p(x\\mid y) \\log q(x) \\mathrm{d}x + \\int p(x\\mid y) \\log p(x\\mid y) \\mathrm{d}x \\end{aligned} $$其中，$\\int p(x\\mid y) \\log q(x) \\mathrm{d}x$ 实质上是 $p$ 与 $q$ 之间的交叉熵，不妨定义 $H(p, q) = \\int p(x\\mid y) \\log q(x) \\mathrm{d}x$。而 $\\int p(x\\mid y) \\log p(x\\mid y) \\mathrm{d}x$ 则是关于 $p$ 的熵。$p$ 的熵实质上是一个常数，因此实质上：\n","keywords":["Variational Inference","Bayesian Inference","KL Divergence","ELBO"],"articleBody":"1. 动机 对于一个状态 $x$，在通过传感器进行一次观测 $y$ 后，我们希望可以计算出后验分布 $p(x\\mid y)$，即在观测到 $y$ 的情况下，状态 $x$ 的分布。为了计算后验分布的形式，我们可以使用贝叶斯公式：\n$$ \\begin{aligned} p(x\\mid y) \u0026= \\frac{p(y\\mid x) p(x)}{p(y)}\\\\ \u0026= \\frac{p(y\\mid x) p(x)}{\\int p(y\\mid x) p(x) \\mathrm{d}x} \\end{aligned} $$对于状态估计问题，我们只需要找到使得 $p(x\\mid y)$ 最大的状态 $x$。 由于 $p(y)$ 是一个常数，我们可以将其忽略，只需要最大化分子部分。但是一些应用场景中，还需要我们计算出具体的后验分布的形式。但是这往往非常的难，边缘似然 $p(y)$ 的计算往往是几乎不可能的。因此一个或许可行的办法是，使用一个相对简单的分布 $q(x)$ 代替后验分布。那么原本的贝叶斯问题变成一个变分优化问题，不妨用 KL 散度衡量差异。\n2. KL 散度的不对称性 但是一个很核心的问题是，KL 散度不具有对称性，$D_{KL}(p\\| q) \\neq D_{KL}(q\\| p)$，在实际操作中，我们应该如何选择？不妨先观察这两个对称的 KL 散度的具体形式：\n$$ \\begin{aligned} D_{KL}(p \\| q) \u0026= -\\int p(x\\mid y) \\log \\frac{q(x)}{p(x\\mid y)} \\mathrm{d}x\\\\ \u0026= -\\int p(x\\mid y) \\log q(x) \\mathrm{d}x + \\int p(x\\mid y) \\log p(x\\mid y) \\mathrm{d}x \\end{aligned} $$其中，$\\int p(x\\mid y) \\log q(x) \\mathrm{d}x$ 实质上是 $p$ 与 $q$ 之间的交叉熵，不妨定义 $H(p, q) = \\int p(x\\mid y) \\log q(x) \\mathrm{d}x$。而 $\\int p(x\\mid y) \\log p(x\\mid y) \\mathrm{d}x$ 则是关于 $p$ 的熵。$p$ 的熵实质上是一个常数，因此实质上：\n$$ \\begin{aligned} \\arg \\min_q D_{KL}(p \\| q) \u0026= \\arg \\max \\int p(x\\mid y) \\log q(x) \\mathrm{d}x\\\\ \u0026= \\arg \\max H(p, q) \\end{aligned} $$因此优化 $D_{KL}(p \\| q)$ 实质上相当于优化 $p$ 与 $q$ 之间的交叉熵。观察交叉熵的形式不难发现，我们事实上是在一个固定的权重 $p$ 下，最大化 $-\\log q$。因此分布 $p$ 不能偷懒，需要在 $p$ 所有足够大的地方让 $q$ 也足够大。我们不难推导出，$D_{KL}(p \\| q)$ 会强迫 $q$ 尽可能的覆盖 $p$ 的所有高概率区域。\n在这个理解的基础上，我们不妨观察 $D_{KL}(q\\| p)$，有：\n$$ \\begin{aligned} D_{KL}(q\\| p) \u0026= -\\int q(x) \\log \\frac{p(x\\mid y)}{q(x)} \\mathrm{d}x\\\\ \u0026= -\\int q(x) \\log p(x\\mid y) \\mathrm{d}x + \\int q(x) \\log q(x) \\mathrm{d}x \\end{aligned} $$因此，优化\n同样地，定义 $H(q, p) = \\int q(x) \\log p(x\\mid y) \\mathrm{d}x$，q 的熵有 $H(q) =-\\int q(x) \\log q(x) \\mathrm{d}x$。那么优化这个形式下的 KL 散度的形式可以写成：\n$$ \\begin{aligned} \\arg \\min_q D_{KL}(q\\| p) \u0026= \\argmax_q H(q, p)\\\\ \u0026= \\argmax_q \\int q(x) \\log p(x\\mid y) \\mathrm{d}x + \\int q(x) \\log q(x) \\mathrm{d}x\\\\ \u0026= \\argmax_q H(q, p) + H(q) \\end{aligned} $$类似的角度分析，优化 $D_{KL}(p \\| q)$ 实质上是在最大化 $q$ 与 $p$ 的交叉熵的基础上增加一个负熵的正则化，交叉熵 $H(q, p)$ 实质上是在固定了信息分布 $\\log p$ 的情况下，通过优化权重分布 $q$ 来最大化期望。此时 $q$ 有更大的自由度，可以不需要尽可能的完全覆盖，对于无法完美覆盖的区域我们可以直接通过降低权重忽略掉。但是这带来一个问题，如果只用交叉熵损失，$q$ 有一个讨巧的方法，可以学习一个 Dirac Distribution，直接把所有的概率质量都集中在 $p$ 的最大值处。为了避免这个情况出现，负熵正则化 $H(q)$ 则强迫模 $q$ 不那么集中，学习一个更 “宽” 的分布。因此，$D_{KL}(q\\| p)$ 会强迫 $q$ 尽可能地集中在 $p$ 的某一个高概率区域，而忽略掉其他的高概率区域。\n如果 $p(x)$ 是一个多峰分布，那么选择不同的 KL 散度对 $q(x)$ 的影响很明显：\n其中 图(a) 是通过 $D_{KL}(p\\| q)$ 驱动学习的 $q(x)$，而 (b) 和 (c) 则是在不同初始下通过 $D_{KL}(q\\| p)$ 学习的 $q(x)$。可以看到 (a) 中的 $q(x)$ 覆盖了 $p(x)$ 的所有高概率区域，而 (b) 和 (c) 则分别集中在 $p(x)$ 的不同峰值处。\n从这个角度分析，不难得出这样的结论：\n如果我们希望我们的模型 $q$ 需要尽可能的覆盖真实分布 $p$，为此可以牺牲模型一定的准确性，则应该选择 $D_{KL}(p\\| q)$。 如果我们希望模型 $q$ 尽可能的准确，为了准确性可以放弃一些 corner case，则可以选择 $D_{KL}(q\\| p)$。 因为 $q$ 是解析的，$D_{KL}(q\\| p)$ 通常更容易计算。 3. Bayesian 推断和 ELBO 对于 Bayesian Inference 问题，我们无法计算后验分布 $p(x\\mid y)$，也无法很容易的对其采样。想直接计算 $D_{KL}(p \\| q)$ 是非常困难的。因此我们选择优化 $D_{KL}(q\\| p)$。但是这个形式无法直接计算，不妨展开这个形式分析：\n$$ \\begin{aligned} D_{KL}(q\\| p) \u0026= -\\int q(x) \\log \\frac{p(x\\mid y)}{q(x)} \\mathrm{d}x\\\\ \u0026= -\\int q(x) \\bigg[\\log p(x\\mid y) - \\log q(x)\\bigg] \\mathrm{d}x\\\\ \u0026= -\\int q(x) \\bigg[\\log p(y\\mid x) + \\log p(x) - \\log p(y)- \\log q(x)\\bigg] \\mathrm{d}x\\\\ \u0026= \\mathbb{E}_{x\\sim q}\\bigg[\\log p(y\\mid x) + \\log p(x) - \\log q(x)\\bigg] - \\mathbb{E}_{x\\sim q}\\bigg[\\log p(y)\\bigg] \\end{aligned} $$其中，显然有：\n$$ \\begin{aligned} \\mathbb{E}_{x\\sim q}\\big[ \\log p(y)\\big] = \\log p(y) \\end{aligned} $$那么，这个形式可以变换为：\n$$ \\begin{aligned} D_{KL}(q\\| p) \u0026= \\mathbb{E}_{x\\sim q}\\bigg[\\log p(y\\mid x)\\bigg] - D_{KL}(q(x) \\| p(x)) - \\log p(y) \\end{aligned} $$显然 $\\log p(y)$ 是一个常数，因此优化 $D_{KL}(q\\| p)$ 等价于优化：\n$$ D_{KL}(q\\| p) \\sim \\mathbb{E}_{x\\sim q}\\bigg[\\log p(y\\mid x)\\bigg] - D_{KL}(q(x) \\| p(x)) $$这个形式就是 ELBO (Evidence Lower Bound)。我们可以定义：\n$$ \\text{ELBO}(q) = \\mathbb{E}_{x\\sim q}\\bigg[\\log p(y\\mid x)\\bigg] - D_{KL}(q(x) \\| p(x)) $$对于 ELBO，我们还有一个等价的形式。观察上面的推导过程，不难发现：\n$$ \\text{ELBO}(q) = \\mathbb{E}_{x\\sim q}\\bigg[\\log \\frac{p(x, y)}{q(x)}\\bigg] $$此时，$\\text{ELBO}(q)$ 的形式我们都有已经了解了。对于一个受到参数控制分布族 $q$，我们可以通过优化上面的形式来获得对后验最优的估计。\n4. Factorized Variational Inference 4.1. 对于 $D_{KL}(q\\|p)$ 的 Factorized Variational Inference 但是此时对于具体如何优化 ELBO 还没有给出一个具体的方法。下面我们要引入一个比较弱的简化假设。我们假设状态 $x$ 之间不是完全耦合的，可以分解成几个独立的子状态 $x = (x_1, x_2, \\ldots, x_n)$。那么假设的模型分布 $q(x)$ 可以写作：\n$$ q(x) = \\prod_{i=1}^n q_i(x_i) $$要注意的是，我们没有对 $q(x)$ 的具体形式做任何假设，只假设 $q(x)$ 之间有可以分解的独立分量。将假设的 $q(x)$ 的分解形式带入 ELBO 中，有：\n$$ \\begin{aligned} \\text{ELBO}(q) \u0026= \\mathbb{E}_{x\\sim q}\\bigg[\\log \\frac{p(x, y)}{q(x)}\\bigg]\\\\ \u0026= \\int \\prod_{i=1}^n q_i(x_i) \\bigg[\\log p(x, y) - \\sum_i \\log q_i(x_i) \\bigg] \\mathrm{d}x \\end{aligned} $$此处不妨用用 Fubini’s theorem，将 $x_j$ 的分量提取出来，先对 $x_j$ 积分：\n$$ \\begin{aligned} \\text{ELBO}(q) \u0026= \\int_{x_j} q_j(x_j) \\int_{x_{i\\neq j}} \\prod_{i\\neq j} q_i(x_i) \\bigg[\\log p(x, y) - \\sum_{i\\neq j} \\log q_i(x_i) - \\log q_j(x_j) \\bigg] \\mathrm{d}x_{i\\neq j} \\mathrm{d}x_j\\\\ \u0026= \\int_{x_j} q_j(x_j) \\bigg \\{\\int_{x_{i\\neq j}} \\prod_{i\\neq j} q_i(x_i) \\bigg[\\log p(x, y)\\bigg] \\mathrm{d}x_{i\\neq j} \\\\ \u0026- \\int_{x_{i\\neq j}} \\prod_{i\\neq j} q_i(x_i) \\bigg[\\sum_{i\\neq j} \\log q_i(x_i) \\bigg] \\mathrm{d}x_{i\\neq j} - \\int_{x_{i\\neq j}} \\prod_{i\\neq j} q_i(x_i) \\bigg[ \\log q_j(x_j) \\bigg] \\mathrm{d}x_{i\\neq j} \\bigg \\}\\mathrm{d}x_j\\\\ \\end{aligned} $$其中，我们不难发现 $\\int_{x_{i\\neq j}} \\prod_{i\\neq j} q_i(x_i) \\bigg[\\sum_{i\\neq j} \\log q_i(x_i) \\bigg] \\mathrm{d}x_{i\\neq j}$ 是一个与 $x_j$ 无关的常数，不妨直接记作 $C$。此外还有：\n$$ \\begin{aligned} \\int_{x_{i\\neq j}} \\prod_{i\\neq j} q_i(x_i) \\bigg[ \\log qq_j(x_j) \\bigg] \\mathrm{d}x_{i\\neq j} \u0026= \\mathbb{E}_{x\\sim \\prod_{i\\neq j} q_i(x_i)} \\bigg[\\log q_j(x_j)\\bigg]\\\\ \u0026= \\log q_j(x_j) \\end{aligned} $$那么上面的形式可以化简为：\n$$ \\begin{aligned} \\text{ELBO}(q) \u0026= \\int_{x_j} q_j(x_j) \\left \\{\\int_{x_{i\\neq j}} \\log p(x, y) \\left(\\prod_{i\\neq j} q_i(x_i) \\mathrm{d}x_i\\right) - \\log q_j(x_j) \\right\\}\\mathrm{d}x_j \\end{aligned} $$不难看出，上式中的第一项是一个期望的形式，那么有：\n$$ \\int_{x_{i\\neq j}} \\log p(x, y) \\left(\\prod_{i\\neq j} q_i(x_i) \\mathrm{d}x_i\\right) = \\mathbf{E}_{x\\sim \\prod_{i\\neq j} q_i(x_i)} \\big[\\log p(x, y)\\big] $$那么根据玻尔兹曼分布，可以定义一定存在一个分布 $q^*(x_j, y)$，满足：\n$$ \\log q^*(x_j, y) = \\mathbf{E}_{x\\sim \\prod_{i\\neq j} q_i(x_i)} \\big[\\log p(x, y)\\big] + C' $$那么 $\\text{ELBO}(q)$ 可以写成这样的形式：\n$$ \\begin{aligned} \\text{ELBO}(q) = \\int_{x_j} q_j(x_j) \\left[\\log q^*(x_j, y) - \\log q_j(x_j) \\right]\\mathrm{d}x_j \\end{aligned} $$你一定注意到了，这事实上是一个 KL 散度！那么可以写作：\n$$ \\text{ELBO}(q) = -D_{KL}\\big(q_j(x_j) \\| q^*(x_j, y)\\big) $$对上面的形式求最优，事实上就是希望：\n$$ D_{KL}\\big(q_j(x_j) \\| q^*(x_j, y)\\big) = 0 $$那么有：\n$$ \\begin{aligned} \\log q_j(x_j) \u0026= \\log q^*(x_j, y)\\\\ \u0026= \\mathbf{E}_{x\\sim \\prod_{i\\neq j} q_i(x_i)} \\big[\\log p(x, y)\\big] + C' \\end{aligned} $$cool！我们成功的将一个最优化问题变为了一个可以 Monto Carlo 甚至直接解析的解决的期望问题。但是现在还面临一个小麻烦。我们在计算第 $i$ 个字空间的分布时，以来于其他所有字空间的分布。这似乎成了一个先有鸡还是先有蛋的死局。但是精通数值分析的你一定不陌生，我们可以先对所有子空间的分布做一个足够的初始，之后迭代计算即可。\n","wordCount":"770","inLanguage":"en","image":"https://wangjv0812.cn/","datePublished":"2025-10-28T23:35:25+08:00","dateModified":"2025-10-28T23:35:25+08:00","author":{"@type":"Person","name":"WangJV"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://wangjv0812.cn/2025/10/variational-bayesian-inference/"},"publisher":{"@type":"Organization","name":"WangJV Blog","logo":{"@type":"ImageObject","url":"https://wangjv0812.cn/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangjv0812.cn/ accesskey=h title="WangJV Blog (Alt + H)">WangJV Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangjv0812.cn/ title=Home><span>Home</span></a></li><li><a href=https://wangjv0812.cn/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://wangjv0812.cn/resources/ title=Resources><span>Resources</span></a></li><li><a href=https://wangjv0812.cn/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://wangjv0812.cn/search/ title="🔍 Search (Alt + /)" accesskey=/><span>🔍 Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://wangjv0812.cn/>Home</a>&nbsp;»&nbsp;<a href=https://wangjv0812.cn/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Variational Bayesian Inference</h1><div class=post-meta><span title='2025-10-28 23:35:25 +0800 +0800'>October 28, 2025</span>&nbsp;·&nbsp;WangJV&nbsp;|&nbsp;<a href=https://github.com/WangJV0812/WangJV-Blog-Source/tree/master/content/posts/Variational%20Bayesian%20Inference/index.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-动机>1. 动机</a></li><li><a href=#2-kl-散度的不对称性>2. KL 散度的不对称性</a></li><li><a href=#3-bayesian-推断和-elbo>3. Bayesian 推断和 ELBO</a></li><li><a href=#4-factorized-variational-inference>4. Factorized Variational Inference</a><ul><li><a href=#41-对于--的-factorized-variational-inference>4.1. 对于 的 Factorized Variational Inference</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=1-动机>1. 动机<a hidden class=anchor aria-hidden=true href=#1-动机>#</a></h2><p>对于一个状态 $x$，在通过传感器进行一次观测 $y$ 后，我们希望可以计算出后验分布 $p(x\mid y)$，即在观测到 $y$ 的情况下，状态 $x$ 的分布。为了计算后验分布的形式，我们可以使用贝叶斯公式：</p>$$
\begin{aligned}
p(x\mid y)
&= \frac{p(y\mid x) p(x)}{p(y)}\\
&= \frac{p(y\mid x) p(x)}{\int p(y\mid x) p(x) \mathrm{d}x}
\end{aligned}
$$<p>对于状态估计问题，我们只需要找到使得 $p(x\mid y)$ 最大的状态 $x$。 由于 $p(y)$ 是一个常数，我们可以将其忽略，只需要最大化分子部分。但是一些应用场景中，还需要我们计算出具体的后验分布的形式。但是这往往非常的难，边缘似然 $p(y)$ 的计算往往是几乎不可能的。因此一个或许可行的办法是，使用一个相对简单的分布 $q(x)$ 代替后验分布。那么原本的贝叶斯问题变成一个变分优化问题，不妨用 KL 散度衡量差异。</p><h2 id=2-kl-散度的不对称性>2. KL 散度的不对称性<a hidden class=anchor aria-hidden=true href=#2-kl-散度的不对称性>#</a></h2><p>但是一个很核心的问题是，KL 散度不具有对称性，$D_{KL}(p\| q) \neq D_{KL}(q\| p)$，在实际操作中，我们应该如何选择？不妨先观察这两个对称的 KL 散度的具体形式：</p>$$
\begin{aligned}
D_{KL}(p \| q)
&= -\int p(x\mid y) \log \frac{q(x)}{p(x\mid y)} \mathrm{d}x\\
&= -\int p(x\mid y) \log q(x) \mathrm{d}x + \int p(x\mid y) \log p(x\mid y) \mathrm{d}x
\end{aligned}
$$<p>其中，$\int p(x\mid y) \log q(x) \mathrm{d}x$ 实质上是 $p$ 与 $q$ 之间的交叉熵，不妨定义 $H(p, q) = \int p(x\mid y) \log q(x) \mathrm{d}x$。而 $\int p(x\mid y) \log p(x\mid y) \mathrm{d}x$ 则是关于 $p$ 的熵。$p$ 的熵实质上是一个常数，因此实质上：</p>$$
\begin{aligned}
\arg \min_q D_{KL}(p \| q)
&= \arg \max \int p(x\mid y) \log q(x) \mathrm{d}x\\
&= \arg \max H(p, q)
\end{aligned}
$$<p>因此优化 $D_{KL}(p \| q)$ 实质上相当于优化 $p$ 与 $q$ 之间的交叉熵。观察交叉熵的形式不难发现，我们事实上是在一个固定的权重 $p$ 下，最大化 $-\log q$。因此分布 $p$ 不能偷懒，需要在 $p$ 所有足够大的地方让 $q$ 也足够大。我们不难推导出，<strong>$D_{KL}(p \| q)$ 会强迫 $q$ 尽可能的覆盖 $p$ 的所有高概率区域。</strong></p><p>在这个理解的基础上，我们不妨观察 $D_{KL}(q\| p)$，有：</p>$$
\begin{aligned}
D_{KL}(q\| p)
&= -\int q(x) \log \frac{p(x\mid y)}{q(x)} \mathrm{d}x\\
&= -\int q(x) \log p(x\mid y) \mathrm{d}x + \int q(x) \log q(x) \mathrm{d}x
\end{aligned}
$$<p>因此，优化</p><p>同样地，定义 $H(q, p) = \int q(x) \log p(x\mid y) \mathrm{d}x$，q 的熵有 $H(q) =-\int q(x) \log q(x) \mathrm{d}x$。那么优化这个形式下的 KL 散度的形式可以写成：</p>$$
\begin{aligned}
\arg \min_q D_{KL}(q\| p)
&= \argmax_q H(q, p)\\
&= \argmax_q \int q(x) \log p(x\mid y) \mathrm{d}x + \int q(x) \log q(x) \mathrm{d}x\\
&= \argmax_q H(q, p) + H(q)
\end{aligned}
$$<p>类似的角度分析，优化 $D_{KL}(p \| q)$ 实质上是在最大化 $q$ 与 $p$ 的交叉熵的基础上增加一个负熵的正则化，交叉熵 $H(q, p)$ 实质上是在固定了信息分布 $\log p$ 的情况下，通过优化权重分布 $q$ 来最大化期望。此时 $q$ 有更大的自由度，可以不需要尽可能的完全覆盖，对于无法完美覆盖的区域我们可以直接通过降低权重忽略掉。但是这带来一个问题，如果只用交叉熵损失，$q$ 有一个讨巧的方法，可以学习一个 Dirac Distribution，直接把所有的概率质量都集中在 $p$ 的最大值处。为了避免这个情况出现，负熵正则化 $H(q)$ 则强迫模 $q$ 不那么集中，学习一个更 “宽” 的分布。因此，<strong>$D_{KL}(q\| p)$ 会强迫 $q$ 尽可能地集中在 $p$ 的某一个高概率区域，而忽略掉其他的高概率区域。</strong></p><p>如果 $p(x)$ 是一个多峰分布，那么选择不同的 KL 散度对 $q(x)$ 的影响很明显：</p><p><img alt="comparison of alternative KL Divergence" loading=lazy src=https://wangjv0812.cn/2025/10/variational-bayesian-inference/Images/Comparison_of_Alternative_KL.png></p><p>其中 图(a) 是通过 $D_{KL}(p\| q)$ 驱动学习的 $q(x)$，而 (b) 和 (c) 则是在不同初始下通过 $D_{KL}(q\| p)$ 学习的 $q(x)$。可以看到 (a) 中的 $q(x)$ 覆盖了 $p(x)$ 的所有高概率区域，而 (b) 和 (c) 则分别集中在 $p(x)$ 的不同峰值处。</p><p>从这个角度分析，不难得出这样的结论：</p><ol><li>如果我们希望我们的模型 $q$ 需要尽可能的覆盖真实分布 $p$，为此可以牺牲模型一定的准确性，则应该选择 $D_{KL}(p\| q)$。</li><li>如果我们希望模型 $q$ 尽可能的准确，为了准确性可以放弃一些 corner case，则可以选择 $D_{KL}(q\| p)$。</li><li>因为 $q$ 是解析的，$D_{KL}(q\| p)$ 通常更容易计算。</li></ol><h2 id=3-bayesian-推断和-elbo>3. Bayesian 推断和 ELBO<a hidden class=anchor aria-hidden=true href=#3-bayesian-推断和-elbo>#</a></h2><p>对于 Bayesian Inference 问题，我们无法计算后验分布 $p(x\mid y)$，也无法很容易的对其采样。想直接计算 $D_{KL}(p \| q)$ 是非常困难的。因此我们选择优化 $D_{KL}(q\| p)$。但是这个形式无法直接计算，不妨展开这个形式分析：</p>$$
\begin{aligned}
D_{KL}(q\| p)
&= -\int q(x) \log \frac{p(x\mid y)}{q(x)} \mathrm{d}x\\
&= -\int q(x) \bigg[\log p(x\mid y) - \log q(x)\bigg] \mathrm{d}x\\
&= -\int q(x) \bigg[\log p(y\mid x) + \log p(x) - \log p(y)- \log q(x)\bigg] \mathrm{d}x\\
&= \mathbb{E}_{x\sim q}\bigg[\log p(y\mid x) + \log p(x) - \log q(x)\bigg] - \mathbb{E}_{x\sim q}\bigg[\log p(y)\bigg]
\end{aligned}
$$<p>其中，显然有：</p>$$
\begin{aligned}
\mathbb{E}_{x\sim q}\big[ \log p(y)\big] = \log p(y)
\end{aligned}
$$<p>那么，这个形式可以变换为：</p>$$
\begin{aligned}
D_{KL}(q\| p)
&= \mathbb{E}_{x\sim q}\bigg[\log p(y\mid x)\bigg] - D_{KL}(q(x) \| p(x)) - \log p(y)
\end{aligned}
$$<p>显然 $\log p(y)$ 是一个常数，因此优化 $D_{KL}(q\| p)$ 等价于优化：</p>$$
D_{KL}(q\| p) \sim \mathbb{E}_{x\sim q}\bigg[\log p(y\mid x)\bigg] - D_{KL}(q(x) \| p(x))
$$<p>这个形式就是 ELBO (Evidence Lower Bound)。我们可以定义：</p>$$
\text{ELBO}(q) = \mathbb{E}_{x\sim q}\bigg[\log p(y\mid x)\bigg] - D_{KL}(q(x) \| p(x))
$$<p>对于 ELBO，我们还有一个等价的形式。观察上面的推导过程，不难发现：</p>$$
\text{ELBO}(q) = \mathbb{E}_{x\sim q}\bigg[\log \frac{p(x, y)}{q(x)}\bigg]
$$<p>此时，$\text{ELBO}(q)$ 的形式我们都有已经了解了。对于一个受到参数控制分布族 $q$，我们可以通过优化上面的形式来获得对后验最优的估计。</p><h2 id=4-factorized-variational-inference>4. Factorized Variational Inference<a hidden class=anchor aria-hidden=true href=#4-factorized-variational-inference>#</a></h2><h3 id=41-对于--的-factorized-variational-inference>4.1. 对于 $D_{KL}(q\|p)$ 的 Factorized Variational Inference<a hidden class=anchor aria-hidden=true href=#41-对于--的-factorized-variational-inference>#</a></h3><p>但是此时对于具体如何优化 ELBO 还没有给出一个具体的方法。下面我们要引入一个比较弱的简化假设。我们假设状态 $x$ 之间不是完全耦合的，可以分解成几个独立的子状态 $x = (x_1, x_2, \ldots, x_n)$。那么假设的模型分布 $q(x)$ 可以写作：</p>$$
q(x) = \prod_{i=1}^n q_i(x_i)
$$<p>要注意的是，我们没有对 $q(x)$ 的具体形式做任何假设，只假设 $q(x)$ 之间有可以分解的独立分量。将假设的 $q(x)$ 的分解形式带入 ELBO 中，有：</p>$$
\begin{aligned}
\text{ELBO}(q)
&= \mathbb{E}_{x\sim q}\bigg[\log \frac{p(x, y)}{q(x)}\bigg]\\
&= \int \prod_{i=1}^n q_i(x_i) \bigg[\log p(x, y) - \sum_i \log q_i(x_i) \bigg] \mathrm{d}x
\end{aligned}
$$<p>此处不妨用用 Fubini&rsquo;s theorem，将 $x_j$ 的分量提取出来，先对 $x_j$ 积分：</p>$$
\begin{aligned}
\text{ELBO}(q)
&= \int_{x_j} q_j(x_j) \int_{x_{i\neq j}} \prod_{i\neq j} q_i(x_i) \bigg[\log p(x, y) - \sum_{i\neq j} \log q_i(x_i) - \log q_j(x_j) \bigg] \mathrm{d}x_{i\neq j} \mathrm{d}x_j\\
&= \int_{x_j} q_j(x_j) \bigg \{\int_{x_{i\neq j}} \prod_{i\neq j} q_i(x_i) \bigg[\log p(x, y)\bigg] \mathrm{d}x_{i\neq j} \\
&- \int_{x_{i\neq j}} \prod_{i\neq j} q_i(x_i) \bigg[\sum_{i\neq j} \log q_i(x_i) \bigg] \mathrm{d}x_{i\neq j} - \int_{x_{i\neq j}} \prod_{i\neq j} q_i(x_i) \bigg[ \log q_j(x_j) \bigg] \mathrm{d}x_{i\neq j} \bigg \}\mathrm{d}x_j\\
\end{aligned}
$$<p>其中，我们不难发现 $\int_{x_{i\neq j}} \prod_{i\neq j} q_i(x_i) \bigg[\sum_{i\neq j} \log q_i(x_i) \bigg] \mathrm{d}x_{i\neq j}$ 是一个与 $x_j$ 无关的常数，不妨直接记作 $C$。此外还有：</p>$$
\begin{aligned}
\int_{x_{i\neq j}} \prod_{i\neq j} q_i(x_i) \bigg[ \log qq_j(x_j) \bigg] \mathrm{d}x_{i\neq j}
&= \mathbb{E}_{x\sim \prod_{i\neq j} q_i(x_i)} \bigg[\log q_j(x_j)\bigg]\\
&= \log q_j(x_j)
\end{aligned}
$$<p>那么上面的形式可以化简为：</p>$$
\begin{aligned}
\text{ELBO}(q)
&= \int_{x_j} q_j(x_j) \left \{\int_{x_{i\neq j}} \log p(x, y) \left(\prod_{i\neq j} q_i(x_i) \mathrm{d}x_i\right) - \log q_j(x_j) \right\}\mathrm{d}x_j
\end{aligned}
$$<p>不难看出，上式中的第一项是一个期望的形式，那么有：</p>$$
\int_{x_{i\neq j}} \log p(x, y) \left(\prod_{i\neq j} q_i(x_i) \mathrm{d}x_i\right) = \mathbf{E}_{x\sim \prod_{i\neq j} q_i(x_i)} \big[\log p(x, y)\big]
$$<p>那么根据玻尔兹曼分布，可以定义一定存在一个分布 $q^*(x_j, y)$，满足：</p>$$
\log q^*(x_j, y) = \mathbf{E}_{x\sim \prod_{i\neq j} q_i(x_i)} \big[\log p(x, y)\big] + C'
$$<p>那么 $\text{ELBO}(q)$ 可以写成这样的形式：</p>$$
\begin{aligned}
\text{ELBO}(q) = \int_{x_j} q_j(x_j) \left[\log q^*(x_j, y) - \log q_j(x_j) \right]\mathrm{d}x_j
\end{aligned}
$$<p>你一定注意到了，这事实上是一个 KL 散度！那么可以写作：</p>$$
\text{ELBO}(q) = -D_{KL}\big(q_j(x_j) \| q^*(x_j, y)\big)
$$<p>对上面的形式求最优，事实上就是希望：</p>$$
D_{KL}\big(q_j(x_j) \| q^*(x_j, y)\big) = 0
$$<p>那么有：</p>$$
\begin{aligned}
\log q_j(x_j)
&= \log q^*(x_j, y)\\
&= \mathbf{E}_{x\sim \prod_{i\neq j} q_i(x_i)} \big[\log p(x, y)\big] + C'
\end{aligned}
$$<p>cool！我们成功的将一个最优化问题变为了一个可以 Monto Carlo 甚至直接解析的解决的期望问题。但是现在还面临一个小麻烦。我们在计算第 $i$ 个字空间的分布时，以来于其他所有字空间的分布。这似乎成了一个先有鸡还是先有蛋的死局。但是精通数值分析的你一定不陌生，我们可以先对所有子空间的分布做一个足够的初始，之后迭代计算即可。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://wangjv0812.cn/tags/variational-inference/>Variational Inference</a></li><li><a href=https://wangjv0812.cn/tags/bayesian-inference/>Bayesian Inference</a></li><li><a href=https://wangjv0812.cn/tags/kl-divergence/>KL Divergence</a></li><li><a href=https://wangjv0812.cn/tags/elbo/>ELBO</a></li></ul><nav class=paginav><a class=next href=https://wangjv0812.cn/2025/10/variational-autoencoder/><span class=title>Next »</span><br><span>Variational AutoEncoder</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://wangjv0812.cn/>WangJV Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>