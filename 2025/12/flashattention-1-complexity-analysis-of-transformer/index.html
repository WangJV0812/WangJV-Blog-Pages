<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>FlashAttention-1 Complexity Analysis of Transformer | WangJV Blog</title><meta name=keywords content="æ•°å­¦,æ·±åº¦å­¦ä¹ "><meta name=description content="1. çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ
Transformer æ¨¡å‹äº‹å®ä¸Šæ˜¯çŸ©é˜µä¹˜æ³•çš„å †å ã€‚è®©æˆ‘ä»¬å…ˆä»åŸºç¡€çš„å‘é‡ä¹˜æ³•çš„å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä¸€æ­¥æ­¥æ‰©å±•åˆ°å¯¹å¼ é‡è¿ç®—çš„å¤æ‚åº¦æœ‰æ¸…æ™°çš„è®¤è¯†ã€‚

å¯¹äºå‘é‡ $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$ï¼Œé‚£ä¹ˆå‘é‡ä¹‹é—´çš„ç‚¹ç§¯éœ€è¦è¿›è¡Œ $n$ æ¬¡ä¹˜æ³•å’Œ $n$ æ¬¡åŠ æ³•ï¼Œæ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2n)$ã€‚
å¯¹äºçŸ©é˜µ $\mathbf{A} \in \mathbb{R}^{m \times n}$ å’Œ $\mathbf{x} \in \mathbb{R}^{n}$ï¼ŒçŸ©é˜µå‘é‡ä¹˜æ³• $\mathbf{Ax}$ éœ€è¦è¿›è¡Œ $m$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mn)$ã€‚
å¯¹äºçŸ©é˜µ $\mathbf{A} \in \mathbb{R}^{m\times n}, \mathbf{B} \in \mathbb{R}^{n\times p}$ï¼ŒçŸ©é˜µä¹˜æ³• $\mathbf{AB}$ éœ€è¦è¿›è¡Œ $m \times p$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mnp)$ã€‚

ä¸Šé¢è®¨è®ºäº†åŸºç¡€çŸ©é˜µè¿ç®—çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¸‹é¢ä¸å¦¨ä¸Šä¸Šå¼ºåº¦ï¼Œçœ‹çœ‹å¼ é‡è¿ç®—çš„å¤æ‚åº¦ã€‚å¯¹äºå¼ é‡ $\mathbf{A} \in \mathbb{R}^{{\color{red}{GH}} IJ \color{blue}{KL}}, \mathbf{B} \in \mathbb{R}^{{\color{red}{GH}} MN \color{blue}{KL}}$ï¼Œå…¶ä¸­ç»´åº¦ $\color{red}GH$ æ˜¯ batch ç»´åº¦ï¼Œ$\color{blue} KL$ æ˜¯è¢«å¸æ”¶ (Contracting) çš„ç»´åº¦ã€‚é‚£ä¹ˆå¯ä»¥å®šä¹‰ einsum æ“ä½œå¦‚ä¸‹ï¼š
C = torch.einsum('ghijkl,ghmnkl->ghijmn', A, B)
ä¸Šé¢çš„ einsum æ“ä½œä¸­ï¼Œå¼ é‡ $\mathbf{A}$ å’Œ $\mathbf{B}$ åœ¨ç»´åº¦ $\color{red}GH$ ä¸Šæ˜¯å¯¹é½çš„ (Aligned)ï¼Œåœ¨ç»´åº¦ $\color{blue}KL$ ä¸Šæ˜¯è¢«å¸æ”¶çš„ (Contracting)ã€‚é‚£ä¹ˆè¿™ä¸ª einsum æ“ä½œçš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š"><meta name=author content="WangJV"><link rel=canonical href=https://wangjv0812.cn/2025/12/flashattention-1-complexity-analysis-of-transformer/><link crossorigin=anonymous href=https://wangjv0812.cn/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://wangjv0812.cn/icon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://wangjv0812.cn/icon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangjv0812.cn/icon/favicon-32x32.png><link rel=apple-touch-icon href=https://wangjv0812.cn/icon/apple-touch-icon.png><link rel=mask-icon href=https://wangjv0812.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://wangjv0812.cn/2025/12/flashattention-1-complexity-analysis-of-transformer/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=icon type=image/png sizes=32x32 href=https://wangjv0812.cn/icon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://wangjv0812.cn/icon/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=https://wangjv0812.cn/icon/apple-touch-icon.png><link rel=manifest href=https://wangjv0812.cn/icon/site.webmanifest><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},chtml:{scale:1,minScale:.5,matchFontHeight:!1,displayAlign:"center",displayIndent:"0",mtextInheritFont:!1,merrorInheritFont:!0,mathmlSpacing:!1,skipHtmlTags:["script","noscript","style","textarea","pre","code","a"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"},svg:{scale:1,minScale:.5,mtextInheritFont:!1,merrorInheritFont:!0,mathmlSpacing:!1,skipHtmlTags:["script","noscript","style","textarea","pre","code","a"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"},options:{enableMenu:!0,menuOptions:{settings:{zoom:"Click"}}},loader:{load:["ui/safe","a11y/assistive-mml"]},startup:{ready(){MathJax.startup.defaultReady();const e=new ResizeObserver(e=>{MathJax.typesetPromise()});e.observe(document.body)}}},window.innerWidth<=768&&(MathJax.chtml=MathJax.chtml||{},MathJax.chtml.scale=.9)</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><style>.MathJax{outline:0}@media(max-width:768px){.MathJax{font-size:90%!important}.MathJax_Display{overflow-x:auto;overflow-y:hidden;padding:0!important;margin:1em 0!important}.MathJax_CHTML{line-height:1.2!important}}mjx-container[jax=CHTML][display=true]{overflow-x:auto;overflow-y:hidden;padding:1px 0}</style><meta property="og:url" content="https://wangjv0812.cn/2025/12/flashattention-1-complexity-analysis-of-transformer/"><meta property="og:site_name" content="WangJV Blog"><meta property="og:title" content="FlashAttention-1 Complexity Analysis of Transformer"><meta property="og:description" content="1. çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ Transformer æ¨¡å‹äº‹å®ä¸Šæ˜¯çŸ©é˜µä¹˜æ³•çš„å †å ã€‚è®©æˆ‘ä»¬å…ˆä»åŸºç¡€çš„å‘é‡ä¹˜æ³•çš„å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä¸€æ­¥æ­¥æ‰©å±•åˆ°å¯¹å¼ é‡è¿ç®—çš„å¤æ‚åº¦æœ‰æ¸…æ™°çš„è®¤è¯†ã€‚
å¯¹äºå‘é‡ $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$ï¼Œé‚£ä¹ˆå‘é‡ä¹‹é—´çš„ç‚¹ç§¯éœ€è¦è¿›è¡Œ $n$ æ¬¡ä¹˜æ³•å’Œ $n$ æ¬¡åŠ æ³•ï¼Œæ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2n)$ã€‚ å¯¹äºçŸ©é˜µ $\mathbf{A} \in \mathbb{R}^{m \times n}$ å’Œ $\mathbf{x} \in \mathbb{R}^{n}$ï¼ŒçŸ©é˜µå‘é‡ä¹˜æ³• $\mathbf{Ax}$ éœ€è¦è¿›è¡Œ $m$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mn)$ã€‚ å¯¹äºçŸ©é˜µ $\mathbf{A} \in \mathbb{R}^{m\times n}, \mathbf{B} \in \mathbb{R}^{n\times p}$ï¼ŒçŸ©é˜µä¹˜æ³• $\mathbf{AB}$ éœ€è¦è¿›è¡Œ $m \times p$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mnp)$ã€‚ ä¸Šé¢è®¨è®ºäº†åŸºç¡€çŸ©é˜µè¿ç®—çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¸‹é¢ä¸å¦¨ä¸Šä¸Šå¼ºåº¦ï¼Œçœ‹çœ‹å¼ é‡è¿ç®—çš„å¤æ‚åº¦ã€‚å¯¹äºå¼ é‡ $\mathbf{A} \in \mathbb{R}^{{\color{red}{GH}} IJ \color{blue}{KL}}, \mathbf{B} \in \mathbb{R}^{{\color{red}{GH}} MN \color{blue}{KL}}$ï¼Œå…¶ä¸­ç»´åº¦ $\color{red}GH$ æ˜¯ batch ç»´åº¦ï¼Œ$\color{blue} KL$ æ˜¯è¢«å¸æ”¶ (Contracting) çš„ç»´åº¦ã€‚é‚£ä¹ˆå¯ä»¥å®šä¹‰ einsum æ“ä½œå¦‚ä¸‹ï¼š
C = torch.einsum('ghijkl,ghmnkl->ghijmn', A, B) ä¸Šé¢çš„ einsum æ“ä½œä¸­ï¼Œå¼ é‡ $\mathbf{A}$ å’Œ $\mathbf{B}$ åœ¨ç»´åº¦ $\color{red}GH$ ä¸Šæ˜¯å¯¹é½çš„ (Aligned)ï¼Œåœ¨ç»´åº¦ $\color{blue}KL$ ä¸Šæ˜¯è¢«å¸æ”¶çš„ (Contracting)ã€‚é‚£ä¹ˆè¿™ä¸ª einsum æ“ä½œçš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-15T15:56:56+08:00"><meta property="article:modified_time" content="2025-12-15T15:56:56+08:00"><meta property="article:tag" content="æ•°å­¦"><meta property="article:tag" content="æ·±åº¦å­¦ä¹ "><meta property="og:image" content="https://wangjv0812.cn/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://wangjv0812.cn/"><meta name=twitter:title content="FlashAttention-1 Complexity Analysis of Transformer"><meta name=twitter:description content="1. çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ
Transformer æ¨¡å‹äº‹å®ä¸Šæ˜¯çŸ©é˜µä¹˜æ³•çš„å †å ã€‚è®©æˆ‘ä»¬å…ˆä»åŸºç¡€çš„å‘é‡ä¹˜æ³•çš„å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä¸€æ­¥æ­¥æ‰©å±•åˆ°å¯¹å¼ é‡è¿ç®—çš„å¤æ‚åº¦æœ‰æ¸…æ™°çš„è®¤è¯†ã€‚

å¯¹äºå‘é‡ $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$ï¼Œé‚£ä¹ˆå‘é‡ä¹‹é—´çš„ç‚¹ç§¯éœ€è¦è¿›è¡Œ $n$ æ¬¡ä¹˜æ³•å’Œ $n$ æ¬¡åŠ æ³•ï¼Œæ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2n)$ã€‚
å¯¹äºçŸ©é˜µ $\mathbf{A} \in \mathbb{R}^{m \times n}$ å’Œ $\mathbf{x} \in \mathbb{R}^{n}$ï¼ŒçŸ©é˜µå‘é‡ä¹˜æ³• $\mathbf{Ax}$ éœ€è¦è¿›è¡Œ $m$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mn)$ã€‚
å¯¹äºçŸ©é˜µ $\mathbf{A} \in \mathbb{R}^{m\times n}, \mathbf{B} \in \mathbb{R}^{n\times p}$ï¼ŒçŸ©é˜µä¹˜æ³• $\mathbf{AB}$ éœ€è¦è¿›è¡Œ $m \times p$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mnp)$ã€‚

ä¸Šé¢è®¨è®ºäº†åŸºç¡€çŸ©é˜µè¿ç®—çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¸‹é¢ä¸å¦¨ä¸Šä¸Šå¼ºåº¦ï¼Œçœ‹çœ‹å¼ é‡è¿ç®—çš„å¤æ‚åº¦ã€‚å¯¹äºå¼ é‡ $\mathbf{A} \in \mathbb{R}^{{\color{red}{GH}} IJ \color{blue}{KL}}, \mathbf{B} \in \mathbb{R}^{{\color{red}{GH}} MN \color{blue}{KL}}$ï¼Œå…¶ä¸­ç»´åº¦ $\color{red}GH$ æ˜¯ batch ç»´åº¦ï¼Œ$\color{blue} KL$ æ˜¯è¢«å¸æ”¶ (Contracting) çš„ç»´åº¦ã€‚é‚£ä¹ˆå¯ä»¥å®šä¹‰ einsum æ“ä½œå¦‚ä¸‹ï¼š
C = torch.einsum('ghijkl,ghmnkl->ghijmn', A, B)
ä¸Šé¢çš„ einsum æ“ä½œä¸­ï¼Œå¼ é‡ $\mathbf{A}$ å’Œ $\mathbf{B}$ åœ¨ç»´åº¦ $\color{red}GH$ ä¸Šæ˜¯å¯¹é½çš„ (Aligned)ï¼Œåœ¨ç»´åº¦ $\color{blue}KL$ ä¸Šæ˜¯è¢«å¸æ”¶çš„ (Contracting)ã€‚é‚£ä¹ˆè¿™ä¸ª einsum æ“ä½œçš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://wangjv0812.cn/posts/"},{"@type":"ListItem","position":2,"name":"FlashAttention-1 Complexity Analysis of Transformer","item":"https://wangjv0812.cn/2025/12/flashattention-1-complexity-analysis-of-transformer/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"FlashAttention-1 Complexity Analysis of Transformer","name":"FlashAttention-1 Complexity Analysis of Transformer","description":"1. çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ Transformer æ¨¡å‹äº‹å®ä¸Šæ˜¯çŸ©é˜µä¹˜æ³•çš„å †å ã€‚è®©æˆ‘ä»¬å…ˆä»åŸºç¡€çš„å‘é‡ä¹˜æ³•çš„å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä¸€æ­¥æ­¥æ‰©å±•åˆ°å¯¹å¼ é‡è¿ç®—çš„å¤æ‚åº¦æœ‰æ¸…æ™°çš„è®¤è¯†ã€‚\nå¯¹äºå‘é‡ $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ï¼Œé‚£ä¹ˆå‘é‡ä¹‹é—´çš„ç‚¹ç§¯éœ€è¦è¿›è¡Œ $n$ æ¬¡ä¹˜æ³•å’Œ $n$ æ¬¡åŠ æ³•ï¼Œæ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2n)$ã€‚ å¯¹äºçŸ©é˜µ $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ å’Œ $\\mathbf{x} \\in \\mathbb{R}^{n}$ï¼ŒçŸ©é˜µå‘é‡ä¹˜æ³• $\\mathbf{Ax}$ éœ€è¦è¿›è¡Œ $m$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mn)$ã€‚ å¯¹äºçŸ©é˜µ $\\mathbf{A} \\in \\mathbb{R}^{m\\times n}, \\mathbf{B} \\in \\mathbb{R}^{n\\times p}$ï¼ŒçŸ©é˜µä¹˜æ³• $\\mathbf{AB}$ éœ€è¦è¿›è¡Œ $m \\times p$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mnp)$ã€‚ ä¸Šé¢è®¨è®ºäº†åŸºç¡€çŸ©é˜µè¿ç®—çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¸‹é¢ä¸å¦¨ä¸Šä¸Šå¼ºåº¦ï¼Œçœ‹çœ‹å¼ é‡è¿ç®—çš„å¤æ‚åº¦ã€‚å¯¹äºå¼ é‡ $\\mathbf{A} \\in \\mathbb{R}^{{\\color{red}{GH}} IJ \\color{blue}{KL}}, \\mathbf{B} \\in \\mathbb{R}^{{\\color{red}{GH}} MN \\color{blue}{KL}}$ï¼Œå…¶ä¸­ç»´åº¦ $\\color{red}GH$ æ˜¯ batch ç»´åº¦ï¼Œ$\\color{blue} KL$ æ˜¯è¢«å¸æ”¶ (Contracting) çš„ç»´åº¦ã€‚é‚£ä¹ˆå¯ä»¥å®šä¹‰ einsum æ“ä½œå¦‚ä¸‹ï¼š\nC = torch.einsum(\u0026#39;ghijkl,ghmnkl-\u0026gt;ghijmn\u0026#39;, A, B) ä¸Šé¢çš„ einsum æ“ä½œä¸­ï¼Œå¼ é‡ $\\mathbf{A}$ å’Œ $\\mathbf{B}$ åœ¨ç»´åº¦ $\\color{red}GH$ ä¸Šæ˜¯å¯¹é½çš„ (Aligned)ï¼Œåœ¨ç»´åº¦ $\\color{blue}KL$ ä¸Šæ˜¯è¢«å¸æ”¶çš„ (Contracting)ã€‚é‚£ä¹ˆè¿™ä¸ª einsum æ“ä½œçš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š\n","keywords":["æ•°å­¦","æ·±åº¦å­¦ä¹ "],"articleBody":"1. çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ Transformer æ¨¡å‹äº‹å®ä¸Šæ˜¯çŸ©é˜µä¹˜æ³•çš„å †å ã€‚è®©æˆ‘ä»¬å…ˆä»åŸºç¡€çš„å‘é‡ä¹˜æ³•çš„å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä¸€æ­¥æ­¥æ‰©å±•åˆ°å¯¹å¼ é‡è¿ç®—çš„å¤æ‚åº¦æœ‰æ¸…æ™°çš„è®¤è¯†ã€‚\nå¯¹äºå‘é‡ $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ï¼Œé‚£ä¹ˆå‘é‡ä¹‹é—´çš„ç‚¹ç§¯éœ€è¦è¿›è¡Œ $n$ æ¬¡ä¹˜æ³•å’Œ $n$ æ¬¡åŠ æ³•ï¼Œæ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2n)$ã€‚ å¯¹äºçŸ©é˜µ $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ å’Œ $\\mathbf{x} \\in \\mathbb{R}^{n}$ï¼ŒçŸ©é˜µå‘é‡ä¹˜æ³• $\\mathbf{Ax}$ éœ€è¦è¿›è¡Œ $m$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mn)$ã€‚ å¯¹äºçŸ©é˜µ $\\mathbf{A} \\in \\mathbb{R}^{m\\times n}, \\mathbf{B} \\in \\mathbb{R}^{n\\times p}$ï¼ŒçŸ©é˜µä¹˜æ³• $\\mathbf{AB}$ éœ€è¦è¿›è¡Œ $m \\times p$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mnp)$ã€‚ ä¸Šé¢è®¨è®ºäº†åŸºç¡€çŸ©é˜µè¿ç®—çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¸‹é¢ä¸å¦¨ä¸Šä¸Šå¼ºåº¦ï¼Œçœ‹çœ‹å¼ é‡è¿ç®—çš„å¤æ‚åº¦ã€‚å¯¹äºå¼ é‡ $\\mathbf{A} \\in \\mathbb{R}^{{\\color{red}{GH}} IJ \\color{blue}{KL}}, \\mathbf{B} \\in \\mathbb{R}^{{\\color{red}{GH}} MN \\color{blue}{KL}}$ï¼Œå…¶ä¸­ç»´åº¦ $\\color{red}GH$ æ˜¯ batch ç»´åº¦ï¼Œ$\\color{blue} KL$ æ˜¯è¢«å¸æ”¶ (Contracting) çš„ç»´åº¦ã€‚é‚£ä¹ˆå¯ä»¥å®šä¹‰ einsum æ“ä½œå¦‚ä¸‹ï¼š\nC = torch.einsum('ghijkl,ghmnkl-\u003eghijmn', A, B) ä¸Šé¢çš„ einsum æ“ä½œä¸­ï¼Œå¼ é‡ $\\mathbf{A}$ å’Œ $\\mathbf{B}$ åœ¨ç»´åº¦ $\\color{red}GH$ ä¸Šæ˜¯å¯¹é½çš„ (Aligned)ï¼Œåœ¨ç»´åº¦ $\\color{blue}KL$ ä¸Šæ˜¯è¢«å¸æ”¶çš„ (Contracting)ã€‚é‚£ä¹ˆè¿™ä¸ª einsum æ“ä½œçš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š\n$$ O\\left(2 \\times G \\times H \\times I \\times J \\times M \\times N \\times K \\times L\\right) $$å³å¯¹äº Batching å’Œ Contracting éƒ½åªä¾¿åˆ©ä¸€éï¼Œè€Œä¸­é—´çš„ç»´åº¦åˆ™éœ€è¦åˆ†åˆ«éå†ã€‚einsum å±•å¼€æ˜¯è¿™æ ·çš„ï¼š\ndef enisum('ghijkl,ghmnkl-\u003eghijmn', A, B): G, H, I, J, K, L = A.shape _, _, M, N, _, _ = B.shape C = torch.zeros((G, H, I, J, M, N)) for g, h, i, j, m, n in product(range(G), range(H), range(I), range(J), range(M), range(N)): sum = 0 for k, l in product(range(K), range(L)): sum += A[g, h, i, j, k, l] * B[g, h, m, n, k, l] C[g, h, i, j, m, n] = sum return C ä¸å¦¨æ€»ç»“ä¸€ä¸‹ï¼Œä¸Šé¢è¿™äº›æ“ä½œçš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š\næ•°æ®ç»´åº¦ å½¢å¼ FLOPs $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ $\\mathbf{xy}$ $O(2n)$ $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}, \\mathbf{x} \\in \\mathbb{R}^{n}$ $\\mathbf{Ax}$ $O(2mn)$ $\\mathbf{A} \\in \\mathbb{R}^{m\\times n}, \\mathbf{B} \\in \\mathbb{R}^{n\\times p}$ $\\mathbf{AB}$ $O(2mnp)$ $\\mathbf{A} \\in \\mathbb{R}^{{\\color{red}{GH}} IJ \\color{blue}{KL}}, \\mathbf{B} \\in \\mathbb{R}^{{\\color{red}{GH}} MN \\color{blue}{KL}}$ einsum(â€˜ghijkl,ghmnkl-\u003eghijmnâ€™, A, B) $O\\left(2 G H I J M N K L\\right)$ 2. åå‘ä¼ æ’­å¤æ‚åº¦åˆ†æ æ¨ç†æ—¶ï¼Œè‡³éœ€è¦è®¡ç®—çŸ©é˜µçš„æ­£å‘è¿ç®—å°±è¡Œï¼Œä½†æ˜¯è®­ç»ƒæ—¶è¦è€ƒè™‘çš„å°±å¤šäº†ï¼Œè¿˜éœ€è¦è®¡ç®— Loss å¯¹å‚æ•°çš„æ¢¯åº¦ã€‚å› æ­¤æœ¬èŠ‚æˆ‘ä»¬è¦åˆ†ææœ€åŸºæœ¬çš„çŸ©é˜µå¾®åˆ†ã€‚\nå¯¹äºä»»æ„å¯ä¼˜åŒ–å˜é‡ $x$ï¼Œå‡è®¾æœ‰ä¸€ä¸ªæ ‡é‡ Loss $L$ï¼Œæƒ³ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ä¼˜åŒ–ï¼Œéœ€è¦æ±‚å¾— $\\frac{\\partial L}{\\partial x}$ã€‚é‚£ä¹ˆå¯¹äº Loss $L$ï¼Œå¯ä»¥å®šä¹‰å…¨å¾®åˆ†ï¼š\n$$ dL = \\sum_{\\forall i \\text{ need optimized}} \\frac{\\partial L}{\\partial x_i} dx_i $$è¿™ä¸ªå½¢å¼ä¸å¤Ÿå¥½å¤„ç†ï¼Œä½†æ˜¯ä¸éš¾å‘ç°è¿™æ°å¥½æ˜¯æ¢¯åº¦çŸ©é˜µ $\\frac{\\partial L}{\\partial x}$ ä¸ $dx$ çš„ Frobenius å†…ç§¯ (Frobenius inner product)ï¼š\n$$ dL = \\text{Tr}\\left(\\left(\\frac{\\partial L}{\\partial x}\\right)^T dx\\right) $$é‚£ä¹ˆå‡è®¾æ­£å‘ä¼ æ’­ä¸­çš„æŸä¸€æ­¥æœ‰ $\\mathbf{C} = \\mathbf{A B}$ï¼Œå¯¹äº $L$ çš„å…¨å¾®åˆ†ï¼Œæœ‰ï¼š\n$$ \\begin{aligned} dL \u0026= \\text{Tr} \\left(\\left( \\frac{\\partial L}{\\partial C}\\right)^T dC\\right)\\\\ \u0026= \\text{Tr} \\left(\\left( \\frac{\\partial L}{\\partial C}\\right)^T A dB\\right)\\\\ \u0026= \\text{Tr} \\left(\\left( \\frac{\\partial L}{\\partial B}\\right)^T dB\\right)\\\\ \\end{aligned} $$é‚£ä¹ˆæœ‰ï¼š\n$$ \\begin{aligned} \\left( \\frac{\\partial L}{\\partial B}\\right)^T \u0026= \\left( \\frac{\\partial L}{\\partial C}\\right)^T A\\\\ \\frac{\\partial L}{\\partial B} \u0026= A^T \\frac{\\partial L}{\\partial C} \\end{aligned} $$æ ¹æ®ä¹‹å‰çš„è®¨è®ºï¼Œè®¡ç®— $\\frac{\\partial L}{\\partial B}$ çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2 m n p)$ã€‚åŒç†å¯å¾—ï¼š\n$$ \\frac{\\partial L}{\\partial A} = \\frac{\\partial L}{\\partial C} B^T $$å°†è¿™äº›åŠ èµ·æ¥ï¼Œå³å¯¹äºçŸ©é˜µä¹˜æ³• $\\mathbf{C} = \\mathbf{A B}$ï¼Œåå‘ä¼ æ’­éœ€è¦è®¡ç®—ä¸‰æ¬¡çŸ©é˜µä¹˜æ³•ï¼Œçš„æ—¶é—´å¤æ‚åº¦æ˜¯ $O(6mnp)$ã€‚ç®€å•çš„è®²ï¼Œå°±æ˜¯æ­£å‘ä¼ æ’­çš„ä¸‰å€ã€‚\nå¦‚æœæˆ‘ä»¬è®¤ä¸º $\\mathbf{A}$ æ˜¯æ•°æ®æµï¼Œ$\\mathbf{B}$ æ˜¯å‚æ•°ï¼Œé‚£ä¹ˆå¯ä»¥å¾—åˆ° openai åœ¨ Scaling Laws for Neural Language Models ä¸­æåˆ°çš„ Trasformer è®­ç»ƒæ—¶éœ€è¦çš„è®¡ç®—é‡ä¸º $6 \\times \\text{å‚æ•°é‡} \\times \\text{token æ•°}$ã€‚\n3. Attention å¤æ‚åº¦åˆ†æ Coolï¼ŒåŸºäºä¸Šé¢çš„è®¨è®ºï¼Œæˆ‘ä»¬å¯ä»¥å…·ä½“çš„åˆ†æ Transformer ä¸­æ¯ä¸€æ­¥çš„æ—¶é—´å¤æ‚åº¦äº†ã€‚\n3.1. Attention æ­£å‘ä¼ æ’­å¤æ‚åº¦åˆ†æ å¯¹äºä¸€ä¸ªè¾“å…¥åºåˆ— $\\mathbf{x} \\in \\mathbb{R}^{B\\times S\\times C}$ï¼Œå’Œå‚æ•° $W_q \\in \\mathbb{R}^{C\\times C_q}, W_k \\in \\mathbb{R}^{C\\times C_q}, W_v \\in \\mathbb{R}^{C\\times C_v}$ï¼Œéœ€è¦å…ˆè®¡ç®—å‡ºæŸ¥è¯¢ (Query)ã€é”® (Key)ã€å€¼ (Value)ï¼š\nQuery = torch.einsum('bsc, cq -\u003e bsq', x, W_q) # B, S, C_q Key = torch.einsum('bsc, cq -\u003e bsq', x, W_k) # B, S, C_q Value = torch.einsum('bsc, cv -\u003e bsv', x, W_v) # B, S, C_v æ ¹æ®ä¹‹å‰çš„è®¨è®ºï¼Œå¯ä»¥å†™å‡ºè¿™ä¸€æ­¥çš„æ—¶é—´å¤æ‚åº¦ï¼š\næ“ä½œ Flops Query $O(2 B S C C_q)$ Key $O(2 B S C C_q)$ Value $O(2 B S C C_v)$ ä¹‹åéœ€è¦å°†è®¡ç®—å‡ºçš„ queryã€keyã€value åˆ’åˆ†å‡º headã€‚å‡è®¾æˆ‘ä»¬é€‰çš„ head æ•°ä¸º $H$ï¼Œä¸” $C_q$ å’Œ $C_v$ éƒ½å¯ä»¥è¢« $H$ æ•´é™¤ï¼Œé‚£ä¹ˆæœ‰ï¼š\nq = q.view(B, S, H, C_q // H).transpose(1, 2).contiguous() # B, H, S, C_q // H k = k.view(B, S, H, C_q // H).transpose(1, 2).contiguous() # B, H, S, C_q // H v = v.view(B, S, H, C_v // H).transpose(1, 2).contiguous() # B, H, S, C_v // H è¿™æ­¥æ²¡æœ‰å…·ä½“çš„è®¡ç®—ï¼Œåªæœ‰æ•°æ®æŒªåŠ¨ã€‚ä¸‹ä¸€æ­¥åˆ™è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° (Attention Scores)ï¼š\nscores = torch.einsum('bhsc, bhtc -\u003e bhst', q, k) / (c_q // H) ** 0.5 # B, H, S, S scores = torch.softmax(scores, dim=-1) è¿™ä¸€æ­¥çš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š\næ“ä½œ Flops scores (einsum) $O(2 B H S S (C_q // H))$ scores (softmax) $O(3 B H S S)$ ä¹‹åå°†æ³¨æ„åŠ›åˆ†æ•°åº”ç”¨åˆ° value ä¸Šï¼Œè®¡ç®—åŠ æƒå’Œå¹¶å°†å¤šå¤´è¿˜åŸï¼š\ncontext = torch.einsum('bhst, bhtv -\u003e bhsv', scores, v) # B, H, S, C_v // H context = context.transpose(1, 2).contiguous() context = context.view(B, S, C_v) # B, S, C_v ä¹‹åï¼Œå†é€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚æ˜ å°„åˆ°è¾“å‡ºç©ºé—´å¹¶æ®‹å·®è¿æ¥ï¼š\noutput = torch.einusm('bsc, cd -\u003e bsd', contrext, W_o) # B, S, C output = output + x # Residual connection è¿™å‡ æ­¥çš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š\næ“ä½œ Flops output (einsum) $O(2 B S C_v C)$ residual connection $O(B S C)$ è¿™æ ·å°±å®Œæˆäº† Attention block çš„æ­£å‘ä¼ æ’­ã€‚åˆ†æä¸­ä¸éš¾å‘ç°ï¼Œæˆ‘ä»¬å¯ä»¥å°† Transformer çš„è®¡ç®—åˆ’åˆ†ä¸ºä¸¤ç±»ï¼š\nå‚æ•°å¯†é›†å‹ (Parameter-bound)ï¼šä¾‹å¦‚çº¿æ€§æŠ•å½± (Linear Projection)ã€FFN ç­‰ã€‚ å¤æ‚åº¦è¿‘ä¼¼ä¸ºï¼š$2 \\times \\text{æ€»å‚æ•°é‡} \\times \\text{token æ•°}$ã€‚ åºåˆ—å¯†é›†å‹ (Sequence-bound)ï¼šä¾‹å¦‚ Attention Score è®¡ç®—ã€Softmax ç­‰ã€‚ å¤æ‚åº¦è¿‘ä¼¼ä¸ºï¼š$2 \\times \\text{å±‚æ•°} \\times O(B \\times C \\times \\text{token æ•°}^2)$ã€‚ 3.2. ä» GPT-3 åˆ° ç°ä»£å¤§æ¨¡å‹ç®—åŠ›ç“¶é¢ˆçš„è½¬ç§» åœ¨ OpenAI å‘è¡¨ Scaling Laws çš„ GPT-3 æ—¶ä»£ï¼ŒTransformer çš„è®¡ç®—ç“¶é¢ˆä¸»è¦åœ¨äºå‚æ•°é‡ã€‚\nä»¥ GPT-3 175B ä¸ºä¾‹ï¼Œæ¨¡å‹å‚æ•°é‡ $P \\approx 1750$ äº¿ï¼Œå±‚æ•° $L=96$ï¼Œéšè—ç»´æ•° $C=12288$ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ $S=2048$ã€‚\nå‚æ•°å¯†é›†å‹è®¡ç®— (Linear)ï¼š $$ 2 \\times 1.75 \\times 10^{11} \\times 2048 \\approx 7 \\times 10^{14} \\text{ FLOPs} $$ åºåˆ—å¯†é›†å‹è®¡ç®— (Attention)ï¼š $$ L \\times 4 \\times B \\times C \\times S^2 = 96 \\times 4 \\times 1 \\times 12288 \\times 2048^2 \\approx 2 \\times 10^{13} \\text{ FLOPs} $$åœ¨ GPT-3 æ—¶ä»£ï¼ŒAttention çš„è®¡ç®—é‡ä»…ä¸ºçº¿æ€§å±‚çš„ $\\frac{1}{35}\\approx 2.8\\%$ï¼Œç¡®å®å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚\nä½†æ˜¯ä»Šæ—¶ä¸åŒå¾€æ—¥ï¼Œç°ä»£æ¨¡å‹ï¼ˆå¦‚ Gemini 2.5 Proï¼‰å°† Context Length æå‡åˆ°äº† 1M çº§åˆ«ã€‚æ­¤æ—¶å‡è®¾æˆ‘ä»¬ç”¨ä¸€ä¸ªåŒæ ·è§„æ¨¡çš„æ¨¡å‹å¤„ç† 1M é•¿åº¦çš„è¾“å…¥ï¼š\nå‚æ•°å¯†é›†å‹è®¡ç®— (Linear)ï¼šç”±äºä¸ $S$ å‘ˆçº¿æ€§å…³ç³»ï¼Œè®¡ç®—é‡å¢é•¿ 500 å€ï¼š $$ 7 \\times 10^{14} \\times 500 \\approx 3.5 \\times 10^{17} \\text{ FLOPs} $$ åºåˆ—å¯†é›†å‹è®¡ç®— (Attention)ï¼šç”±äºä¸ $S$ å‘ˆå¹³æ–¹å…³ç³»ï¼Œè®¡ç®—é‡å¢é•¿ $500^2 = 250,000$ å€ï¼š $$ 2 \\times 10^{13} \\times 250,000 \\approx 5 \\times 10^{18} \\text{ FLOPs} $$å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ 1M ä¸Šä¸‹æ–‡ä¸­ï¼ŒAttention çš„è®¡ç®—é‡åè¶…çº¿æ€§å±‚ 10 å€ä»¥ä¸Šï¼ è®¡ç®—ç“¶é¢ˆä»å‚æ•°è½¬ç§»åˆ°äº†åºåˆ—é•¿åº¦ã€‚è¿™ä¹Ÿè‡ªç„¶çš„å¼•å‡ºäº†æˆ‘ä»¬ä¼˜åŒ– Attention è®¡ç®—çš„åŠ¨æœºã€‚\n","wordCount":"814","inLanguage":"en","image":"https://wangjv0812.cn/","datePublished":"2025-12-15T15:56:56+08:00","dateModified":"2025-12-15T15:56:56+08:00","author":{"@type":"Person","name":"WangJV"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://wangjv0812.cn/2025/12/flashattention-1-complexity-analysis-of-transformer/"},"publisher":{"@type":"Organization","name":"WangJV Blog","logo":{"@type":"ImageObject","url":"https://wangjv0812.cn/icon/favicon-32x32.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangjv0812.cn/ accesskey=h title="WangJV Blog (Alt + H)"><img src=https://wangjv0812.cn/icon/translucent-icon.png alt aria-label=logo height=35>WangJV Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangjv0812.cn/ title=Home><span>Home</span></a></li><li><a href=https://wangjv0812.cn/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://wangjv0812.cn/resources/ title=Resources><span>Resources</span></a></li><li><a href=https://wangjv0812.cn/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://wangjv0812.cn/search/ title="ğŸ” Search (Alt + /)" accesskey=/><span>ğŸ” Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://wangjv0812.cn/>Home</a>&nbsp;Â»&nbsp;<a href=https://wangjv0812.cn/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">FlashAttention-1 Complexity Analysis of Transformer</h1><div class=post-meta><span title='2025-12-15 15:56:56 +0800 +0800'>December 15, 2025</span>&nbsp;Â·&nbsp;WangJV&nbsp;|&nbsp;<a href=https://github.com/WangJV0812/WangJV-Blog-Source/tree/master/content/posts/FlashAttention-1%20Complexity%20Analysis%20of%20Transformer/index.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ>1. çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ</a></li><li><a href=#2-åå‘ä¼ æ’­å¤æ‚åº¦åˆ†æ>2. åå‘ä¼ æ’­å¤æ‚åº¦åˆ†æ</a></li><li><a href=#3-attention-å¤æ‚åº¦åˆ†æ>3. Attention å¤æ‚åº¦åˆ†æ</a><ul><li><a href=#31-attention-æ­£å‘ä¼ æ’­å¤æ‚åº¦åˆ†æ>3.1. Attention æ­£å‘ä¼ æ’­å¤æ‚åº¦åˆ†æ</a></li></ul></li><li><a href=#32-ä»-gpt-3-åˆ°-ç°ä»£å¤§æ¨¡å‹ç®—åŠ›ç“¶é¢ˆçš„è½¬ç§»>3.2. ä» GPT-3 åˆ° ç°ä»£å¤§æ¨¡å‹ç®—åŠ›ç“¶é¢ˆçš„è½¬ç§»</a></li></ul></nav></div></details></div><div class=post-content><h2 id=1-çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ>1. çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ<a hidden class=anchor aria-hidden=true href=#1-çŸ©é˜µè¿ç®—å¤æ‚åº¦åˆ†æ>#</a></h2><p>Transformer æ¨¡å‹äº‹å®ä¸Šæ˜¯çŸ©é˜µä¹˜æ³•çš„å †å ã€‚è®©æˆ‘ä»¬å…ˆä»åŸºç¡€çš„å‘é‡ä¹˜æ³•çš„å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä¸€æ­¥æ­¥æ‰©å±•åˆ°å¯¹å¼ é‡è¿ç®—çš„å¤æ‚åº¦æœ‰æ¸…æ™°çš„è®¤è¯†ã€‚</p><ul><li>å¯¹äºå‘é‡ $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$ï¼Œé‚£ä¹ˆå‘é‡ä¹‹é—´çš„ç‚¹ç§¯éœ€è¦è¿›è¡Œ $n$ æ¬¡ä¹˜æ³•å’Œ $n$ æ¬¡åŠ æ³•ï¼Œæ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2n)$ã€‚</li><li>å¯¹äºçŸ©é˜µ $\mathbf{A} \in \mathbb{R}^{m \times n}$ å’Œ $\mathbf{x} \in \mathbb{R}^{n}$ï¼ŒçŸ©é˜µå‘é‡ä¹˜æ³• $\mathbf{Ax}$ éœ€è¦è¿›è¡Œ $m$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mn)$ã€‚</li><li>å¯¹äºçŸ©é˜µ $\mathbf{A} \in \mathbb{R}^{m\times n}, \mathbf{B} \in \mathbb{R}^{n\times p}$ï¼ŒçŸ©é˜µä¹˜æ³• $\mathbf{AB}$ éœ€è¦è¿›è¡Œ $m \times p$ æ¬¡å‘é‡ç‚¹ç§¯ï¼Œæ¯æ¬¡ç‚¹ç§¯çš„å¤æ‚åº¦ä¸º $O(2n)$ï¼Œå› æ­¤æ€»çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2mnp)$ã€‚</li></ul><p>ä¸Šé¢è®¨è®ºäº†åŸºç¡€çŸ©é˜µè¿ç®—çš„æ—¶é—´å¤æ‚åº¦ï¼Œä¸‹é¢ä¸å¦¨ä¸Šä¸Šå¼ºåº¦ï¼Œçœ‹çœ‹å¼ é‡è¿ç®—çš„å¤æ‚åº¦ã€‚å¯¹äºå¼ é‡ $\mathbf{A} \in \mathbb{R}^{{\color{red}{GH}} IJ \color{blue}{KL}}, \mathbf{B} \in \mathbb{R}^{{\color{red}{GH}} MN \color{blue}{KL}}$ï¼Œå…¶ä¸­ç»´åº¦ $\color{red}GH$ æ˜¯ batch ç»´åº¦ï¼Œ$\color{blue} KL$ æ˜¯è¢«å¸æ”¶ (Contracting) çš„ç»´åº¦ã€‚é‚£ä¹ˆå¯ä»¥å®šä¹‰ <a href=https://docs.pytorch.org/docs/stable/generated/torch.einsum.html>einsum</a> æ“ä½œå¦‚ä¸‹ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>C</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;ghijkl,ghmnkl-&gt;ghijmn&#39;</span><span class=p>,</span> <span class=n>A</span><span class=p>,</span> <span class=n>B</span><span class=p>)</span>
</span></span></code></pre></div><p>ä¸Šé¢çš„ einsum æ“ä½œä¸­ï¼Œå¼ é‡ $\mathbf{A}$ å’Œ $\mathbf{B}$ åœ¨ç»´åº¦ $\color{red}GH$ ä¸Šæ˜¯å¯¹é½çš„ (Aligned)ï¼Œåœ¨ç»´åº¦ $\color{blue}KL$ ä¸Šæ˜¯è¢«å¸æ”¶çš„ (Contracting)ã€‚é‚£ä¹ˆè¿™ä¸ª einsum æ“ä½œçš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š</p>$$
O\left(2 \times G \times H \times I \times J \times M \times N \times K \times L\right)
$$<p>å³å¯¹äº Batching å’Œ Contracting éƒ½åªä¾¿åˆ©ä¸€éï¼Œè€Œä¸­é—´çš„ç»´åº¦åˆ™éœ€è¦åˆ†åˆ«éå†ã€‚einsum å±•å¼€æ˜¯è¿™æ ·çš„ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=k>def</span> <span class=nf>enisum</span><span class=p>(</span><span class=s1>&#39;ghijkl,ghmnkl-&gt;ghijmn&#39;</span><span class=p>,</span> <span class=n>A</span><span class=p>,</span> <span class=n>B</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>G</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>I</span><span class=p>,</span> <span class=n>J</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>L</span> <span class=o>=</span> <span class=n>A</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>M</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>B</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>C</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>G</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>I</span><span class=p>,</span> <span class=n>J</span><span class=p>,</span> <span class=n>M</span><span class=p>,</span> <span class=n>N</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>g</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>,</span> <span class=n>m</span><span class=p>,</span> <span class=n>n</span> <span class=ow>in</span> <span class=n>product</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>G</span><span class=p>),</span> <span class=nb>range</span><span class=p>(</span><span class=n>H</span><span class=p>),</span> <span class=nb>range</span><span class=p>(</span><span class=n>I</span><span class=p>),</span> <span class=nb>range</span><span class=p>(</span><span class=n>J</span><span class=p>),</span> <span class=nb>range</span><span class=p>(</span><span class=n>M</span><span class=p>),</span> <span class=nb>range</span><span class=p>(</span><span class=n>N</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=nb>sum</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>l</span> <span class=ow>in</span> <span class=n>product</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>K</span><span class=p>),</span> <span class=nb>range</span><span class=p>(</span><span class=n>L</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>            <span class=nb>sum</span> <span class=o>+=</span> <span class=n>A</span><span class=p>[</span><span class=n>g</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>,</span> <span class=n>k</span><span class=p>,</span> <span class=n>l</span><span class=p>]</span> <span class=o>*</span> <span class=n>B</span><span class=p>[</span><span class=n>g</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>m</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>k</span><span class=p>,</span> <span class=n>l</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>C</span><span class=p>[</span><span class=n>g</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>,</span> <span class=n>m</span><span class=p>,</span> <span class=n>n</span><span class=p>]</span> <span class=o>=</span> <span class=nb>sum</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>C</span>
</span></span></code></pre></div><p>ä¸å¦¨æ€»ç»“ä¸€ä¸‹ï¼Œä¸Šé¢è¿™äº›æ“ä½œçš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š</p><table><thead><tr><th>æ•°æ®ç»´åº¦</th><th>å½¢å¼</th><th>FLOPs</th></tr></thead><tbody><tr><td>$\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$</td><td>$\mathbf{xy}$</td><td>$O(2n)$</td></tr><tr><td>$\mathbf{A} \in \mathbb{R}^{m \times n}, \mathbf{x} \in \mathbb{R}^{n}$</td><td>$\mathbf{Ax}$</td><td>$O(2mn)$</td></tr><tr><td>$\mathbf{A} \in \mathbb{R}^{m\times n}, \mathbf{B} \in \mathbb{R}^{n\times p}$</td><td>$\mathbf{AB}$</td><td>$O(2mnp)$</td></tr><tr><td>$\mathbf{A} \in \mathbb{R}^{{\color{red}{GH}} IJ \color{blue}{KL}}, \mathbf{B} \in \mathbb{R}^{{\color{red}{GH}} MN \color{blue}{KL}}$</td><td>einsum(&lsquo;ghijkl,ghmnkl->ghijmn&rsquo;, A, B)</td><td>$O\left(2 G H I J M N K L\right)$</td></tr></tbody></table><h2 id=2-åå‘ä¼ æ’­å¤æ‚åº¦åˆ†æ>2. åå‘ä¼ æ’­å¤æ‚åº¦åˆ†æ<a hidden class=anchor aria-hidden=true href=#2-åå‘ä¼ æ’­å¤æ‚åº¦åˆ†æ>#</a></h2><p>æ¨ç†æ—¶ï¼Œè‡³éœ€è¦è®¡ç®—çŸ©é˜µçš„æ­£å‘è¿ç®—å°±è¡Œï¼Œä½†æ˜¯è®­ç»ƒæ—¶è¦è€ƒè™‘çš„å°±å¤šäº†ï¼Œè¿˜éœ€è¦è®¡ç®— Loss å¯¹å‚æ•°çš„æ¢¯åº¦ã€‚å› æ­¤æœ¬èŠ‚æˆ‘ä»¬è¦åˆ†ææœ€åŸºæœ¬çš„çŸ©é˜µå¾®åˆ†ã€‚</p><p>å¯¹äºä»»æ„å¯ä¼˜åŒ–å˜é‡ $x$ï¼Œå‡è®¾æœ‰ä¸€ä¸ªæ ‡é‡ Loss $L$ï¼Œæƒ³ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ä¼˜åŒ–ï¼Œéœ€è¦æ±‚å¾— $\frac{\partial L}{\partial x}$ã€‚é‚£ä¹ˆå¯¹äº Loss $L$ï¼Œå¯ä»¥å®šä¹‰å…¨å¾®åˆ†ï¼š</p>$$
dL = \sum_{\forall i \text{ need optimized}} \frac{\partial L}{\partial x_i} dx_i
$$<p>è¿™ä¸ªå½¢å¼ä¸å¤Ÿå¥½å¤„ç†ï¼Œä½†æ˜¯ä¸éš¾å‘ç°è¿™æ°å¥½æ˜¯æ¢¯åº¦çŸ©é˜µ $\frac{\partial L}{\partial x}$ ä¸ $dx$ çš„ Frobenius å†…ç§¯ (Frobenius inner product)ï¼š</p>$$
dL = \text{Tr}\left(\left(\frac{\partial L}{\partial x}\right)^T dx\right)
$$<p>é‚£ä¹ˆå‡è®¾æ­£å‘ä¼ æ’­ä¸­çš„æŸä¸€æ­¥æœ‰ $\mathbf{C} = \mathbf{A B}$ï¼Œå¯¹äº $L$ çš„å…¨å¾®åˆ†ï¼Œæœ‰ï¼š</p>$$
\begin{aligned}
dL
&= \text{Tr} \left(\left( \frac{\partial L}{\partial C}\right)^T dC\right)\\
&= \text{Tr} \left(\left( \frac{\partial L}{\partial C}\right)^T A dB\right)\\
&= \text{Tr} \left(\left( \frac{\partial L}{\partial B}\right)^T dB\right)\\
\end{aligned}
$$<p>é‚£ä¹ˆæœ‰ï¼š</p>$$
\begin{aligned}
\left( \frac{\partial L}{\partial B}\right)^T &= \left( \frac{\partial L}{\partial C}\right)^T A\\
\frac{\partial L}{\partial B} &= A^T \frac{\partial L}{\partial C}
\end{aligned}
$$<p>æ ¹æ®ä¹‹å‰çš„è®¨è®ºï¼Œè®¡ç®— $\frac{\partial L}{\partial B}$ çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(2 m n p)$ã€‚åŒç†å¯å¾—ï¼š</p>$$
\frac{\partial L}{\partial A} = \frac{\partial L}{\partial C} B^T
$$<p>å°†è¿™äº›åŠ èµ·æ¥ï¼Œå³å¯¹äºçŸ©é˜µä¹˜æ³• $\mathbf{C} = \mathbf{A B}$ï¼Œåå‘ä¼ æ’­éœ€è¦è®¡ç®—ä¸‰æ¬¡çŸ©é˜µä¹˜æ³•ï¼Œçš„æ—¶é—´å¤æ‚åº¦æ˜¯ $O(6mnp)$ã€‚ç®€å•çš„è®²ï¼Œå°±æ˜¯æ­£å‘ä¼ æ’­çš„ä¸‰å€ã€‚</p><p>å¦‚æœæˆ‘ä»¬è®¤ä¸º $\mathbf{A}$ æ˜¯æ•°æ®æµï¼Œ$\mathbf{B}$ æ˜¯å‚æ•°ï¼Œé‚£ä¹ˆå¯ä»¥å¾—åˆ° openai åœ¨ <a href=https://arxiv.org/abs/2001.08361>Scaling Laws for Neural Language Models</a> ä¸­æåˆ°çš„ Trasformer è®­ç»ƒæ—¶éœ€è¦çš„è®¡ç®—é‡ä¸º $6 \times \text{å‚æ•°é‡} \times \text{token æ•°}$ã€‚</p><h2 id=3-attention-å¤æ‚åº¦åˆ†æ>3. Attention å¤æ‚åº¦åˆ†æ<a hidden class=anchor aria-hidden=true href=#3-attention-å¤æ‚åº¦åˆ†æ>#</a></h2><p>Coolï¼ŒåŸºäºä¸Šé¢çš„è®¨è®ºï¼Œæˆ‘ä»¬å¯ä»¥å…·ä½“çš„åˆ†æ Transformer ä¸­æ¯ä¸€æ­¥çš„æ—¶é—´å¤æ‚åº¦äº†ã€‚</p><h3 id=31-attention-æ­£å‘ä¼ æ’­å¤æ‚åº¦åˆ†æ>3.1. Attention æ­£å‘ä¼ æ’­å¤æ‚åº¦åˆ†æ<a hidden class=anchor aria-hidden=true href=#31-attention-æ­£å‘ä¼ æ’­å¤æ‚åº¦åˆ†æ>#</a></h3><p>å¯¹äºä¸€ä¸ªè¾“å…¥åºåˆ— $\mathbf{x} \in \mathbb{R}^{B\times S\times C}$ï¼Œå’Œå‚æ•° $W_q \in \mathbb{R}^{C\times C_q}, W_k \in \mathbb{R}^{C\times C_q}, W_v \in \mathbb{R}^{C\times C_v}$ï¼Œéœ€è¦å…ˆè®¡ç®—å‡ºæŸ¥è¯¢ (Query)ã€é”® (Key)ã€å€¼ (Value)ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>Query</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsc, cq -&gt; bsq&#39;</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>W_q</span><span class=p>)</span> <span class=c1># B, S, C_q</span>
</span></span><span class=line><span class=cl><span class=n>Key</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsc, cq -&gt; bsq&#39;</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>W_k</span><span class=p>)</span> <span class=c1># B, S, C_q</span>
</span></span><span class=line><span class=cl><span class=n>Value</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsc, cv -&gt; bsv&#39;</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>W_v</span><span class=p>)</span> <span class=c1># B, S, C_v</span>
</span></span></code></pre></div><p>æ ¹æ®ä¹‹å‰çš„è®¨è®ºï¼Œå¯ä»¥å†™å‡ºè¿™ä¸€æ­¥çš„æ—¶é—´å¤æ‚åº¦ï¼š</p><table><thead><tr><th>æ“ä½œ</th><th>Flops</th></tr></thead><tbody><tr><td>Query</td><td>$O(2 B S C C_q)$</td></tr><tr><td>Key</td><td>$O(2 B S C C_q)$</td></tr><tr><td>Value</td><td>$O(2 B S C C_v)$</td></tr></tbody></table><p>ä¹‹åéœ€è¦å°†è®¡ç®—å‡ºçš„ queryã€keyã€value åˆ’åˆ†å‡º headã€‚å‡è®¾æˆ‘ä»¬é€‰çš„ head æ•°ä¸º $H$ï¼Œä¸” $C_q$ å’Œ $C_v$ éƒ½å¯ä»¥è¢« $H$ æ•´é™¤ï¼Œé‚£ä¹ˆæœ‰ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>q</span> <span class=o>=</span> <span class=n>q</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>C_q</span> <span class=o>//</span> <span class=n>H</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span> <span class=c1># B, H, S, C_q // H</span>
</span></span><span class=line><span class=cl><span class=n>k</span> <span class=o>=</span> <span class=n>k</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>C_q</span> <span class=o>//</span> <span class=n>H</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span> <span class=c1># B, H, S, C_q // H</span>
</span></span><span class=line><span class=cl><span class=n>v</span> <span class=o>=</span> <span class=n>v</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>C_v</span> <span class=o>//</span> <span class=n>H</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span> <span class=c1># B, H, S, C_v // H</span>
</span></span></code></pre></div><p>è¿™æ­¥æ²¡æœ‰å…·ä½“çš„è®¡ç®—ï¼Œåªæœ‰æ•°æ®æŒªåŠ¨ã€‚ä¸‹ä¸€æ­¥åˆ™è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° (Attention Scores)ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bhsc, bhtc -&gt; bhst&#39;</span><span class=p>,</span> <span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>c_q</span> <span class=o>//</span> <span class=n>H</span><span class=p>)</span> <span class=o>**</span> <span class=mf>0.5</span>  <span class=c1># B, H, S, S</span>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>scores</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><p>è¿™ä¸€æ­¥çš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š</p><table><thead><tr><th>æ“ä½œ</th><th>Flops</th></tr></thead><tbody><tr><td>scores (einsum)</td><td>$O(2 B H S S (C_q // H))$</td></tr><tr><td>scores (softmax)</td><td>$O(3 B H S S)$</td></tr></tbody></table><p>ä¹‹åå°†æ³¨æ„åŠ›åˆ†æ•°åº”ç”¨åˆ° value ä¸Šï¼Œè®¡ç®—åŠ æƒå’Œå¹¶å°†å¤šå¤´è¿˜åŸï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>context</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bhst, bhtv -&gt; bhsv&#39;</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>v</span><span class=p>)</span> <span class=c1># B, H, S, C_v // H</span>
</span></span><span class=line><span class=cl><span class=n>context</span> <span class=o>=</span> <span class=n>context</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>context</span> <span class=o>=</span> <span class=n>context</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>C_v</span><span class=p>)</span> <span class=c1># B, S, C_v </span>
</span></span></code></pre></div><p>ä¹‹åï¼Œå†é€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚æ˜ å°„åˆ°è¾“å‡ºç©ºé—´å¹¶æ®‹å·®è¿æ¥ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>einusm</span><span class=p>(</span><span class=s1>&#39;bsc, cd -&gt; bsd&#39;</span><span class=p>,</span> <span class=n>contrext</span><span class=p>,</span> <span class=n>W_o</span><span class=p>)</span> <span class=c1># B, S, C</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>output</span> <span class=o>+</span> <span class=n>x</span> <span class=c1># Residual connection</span>
</span></span></code></pre></div><p>è¿™å‡ æ­¥çš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š</p><table><thead><tr><th>æ“ä½œ</th><th>Flops</th></tr></thead><tbody><tr><td>output (einsum)</td><td>$O(2 B S C_v C)$</td></tr><tr><td>residual connection</td><td>$O(B S C)$</td></tr></tbody></table><p>è¿™æ ·å°±å®Œæˆäº† Attention block çš„æ­£å‘ä¼ æ’­ã€‚åˆ†æä¸­ä¸éš¾å‘ç°ï¼Œæˆ‘ä»¬å¯ä»¥å°† Transformer çš„è®¡ç®—åˆ’åˆ†ä¸ºä¸¤ç±»ï¼š</p><ol><li><strong>å‚æ•°å¯†é›†å‹ (Parameter-bound)</strong>ï¼šä¾‹å¦‚çº¿æ€§æŠ•å½± (Linear Projection)ã€FFN ç­‰ã€‚
å¤æ‚åº¦è¿‘ä¼¼ä¸ºï¼š$2 \times \text{æ€»å‚æ•°é‡} \times \text{token æ•°}$ã€‚</li><li><strong>åºåˆ—å¯†é›†å‹ (Sequence-bound)</strong>ï¼šä¾‹å¦‚ Attention Score è®¡ç®—ã€Softmax ç­‰ã€‚
å¤æ‚åº¦è¿‘ä¼¼ä¸ºï¼š$2 \times \text{å±‚æ•°} \times O(B \times C \times \text{token æ•°}^2)$ã€‚</li></ol><h2 id=32-ä»-gpt-3-åˆ°-ç°ä»£å¤§æ¨¡å‹ç®—åŠ›ç“¶é¢ˆçš„è½¬ç§»>3.2. ä» GPT-3 åˆ° ç°ä»£å¤§æ¨¡å‹ç®—åŠ›ç“¶é¢ˆçš„è½¬ç§»<a hidden class=anchor aria-hidden=true href=#32-ä»-gpt-3-åˆ°-ç°ä»£å¤§æ¨¡å‹ç®—åŠ›ç“¶é¢ˆçš„è½¬ç§»>#</a></h2><p>åœ¨ OpenAI å‘è¡¨ <a href=https://arxiv.org/abs/2001.08361>Scaling Laws</a> çš„ GPT-3 æ—¶ä»£ï¼ŒTransformer çš„è®¡ç®—ç“¶é¢ˆä¸»è¦åœ¨äºå‚æ•°é‡ã€‚</p><p>ä»¥ <strong>GPT-3 175B</strong> ä¸ºä¾‹ï¼Œæ¨¡å‹å‚æ•°é‡ $P \approx 1750$ äº¿ï¼Œå±‚æ•° $L=96$ï¼Œéšè—ç»´æ•° $C=12288$ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ $S=2048$ã€‚</p><ul><li>å‚æ•°å¯†é›†å‹è®¡ç®— (Linear)ï¼š</li></ul>$$
2 \times 1.75 \times 10^{11} \times 2048 \approx 7 \times 10^{14} \text{ FLOPs}
$$<ul><li>åºåˆ—å¯†é›†å‹è®¡ç®— (Attention)ï¼š</li></ul>$$
L \times 4 \times B \times C \times S^2 = 96 \times 4 \times 1 \times 12288 \times 2048^2 \approx 2 \times 10^{13} \text{ FLOPs}
$$<p>åœ¨ GPT-3 æ—¶ä»£ï¼ŒAttention çš„è®¡ç®—é‡ä»…ä¸ºçº¿æ€§å±‚çš„ $\frac{1}{35}\approx 2.8\%$ï¼Œç¡®å®å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚</p><p>ä½†æ˜¯ä»Šæ—¶ä¸åŒå¾€æ—¥ï¼Œç°ä»£æ¨¡å‹ï¼ˆå¦‚ Gemini 2.5 Proï¼‰å°† Context Length æå‡åˆ°äº† <a href=https://help.magai.co/en/articles/9148741-what-is-an-ai-context-limit-aka-context-window>1M çº§åˆ«</a>ã€‚æ­¤æ—¶å‡è®¾æˆ‘ä»¬ç”¨ä¸€ä¸ªåŒæ ·è§„æ¨¡çš„æ¨¡å‹å¤„ç† 1M é•¿åº¦çš„è¾“å…¥ï¼š</p><ul><li>å‚æ•°å¯†é›†å‹è®¡ç®— (Linear)ï¼šç”±äºä¸ $S$ å‘ˆçº¿æ€§å…³ç³»ï¼Œè®¡ç®—é‡å¢é•¿ 500 å€ï¼š</li></ul>$$
7 \times 10^{14} \times 500 \approx 3.5 \times 10^{17} \text{ FLOPs}
$$<ul><li>åºåˆ—å¯†é›†å‹è®¡ç®— (Attention)ï¼šç”±äºä¸ $S$ å‘ˆå¹³æ–¹å…³ç³»ï¼Œè®¡ç®—é‡å¢é•¿ $500^2 = 250,000$ å€ï¼š</li></ul>$$
2 \times 10^{13} \times 250,000 \approx 5 \times 10^{18} \text{ FLOPs}
$$<p>å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ 1M ä¸Šä¸‹æ–‡ä¸­ï¼ŒAttention çš„è®¡ç®—é‡åè¶…çº¿æ€§å±‚ 10 å€ä»¥ä¸Šï¼ è®¡ç®—ç“¶é¢ˆä»å‚æ•°è½¬ç§»åˆ°äº†åºåˆ—é•¿åº¦ã€‚è¿™ä¹Ÿè‡ªç„¶çš„å¼•å‡ºäº†æˆ‘ä»¬ä¼˜åŒ– Attention è®¡ç®—çš„åŠ¨æœºã€‚</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://wangjv0812.cn/tags/%E6%95%B0%E5%AD%A6/>æ•°å­¦</a></li><li><a href=https://wangjv0812.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>æ·±åº¦å­¦ä¹ </a></li></ul><nav class=paginav><a class=next href=https://wangjv0812.cn/2025/11/lumine-training-an-agent-to-play-genshin/><span class=title>Next Â»</span><br><span>Lumine: Training an Agent to play Genshin</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=WangJV0812/WangJV-Blog-Pages data-repo-id=R_kgDOPZMmQw data-category=comments data-category-id=DIC_kwDOPZMmQ84Czj63 data-mapping=url data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://wangjv0812.cn/>WangJV Blog</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>